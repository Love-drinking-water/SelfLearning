{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1.-Data-Representation\" data-toc-modified-id=\"1.-Data-Representation-1\">1. Data Representation</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.1-张量介绍\" data-toc-modified-id=\"1.1-张量介绍-1.1\">1.1 张量介绍</a></span></li><li><span><a href=\"#1.2-张量计算\" data-toc-modified-id=\"1.2-张量计算-1.2\">1.2 张量计算</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.2.1-逐元素运算\" data-toc-modified-id=\"1.2.1-逐元素运算-1.2.1\">1.2.1 逐元素运算</a></span></li><li><span><a href=\"#1.2.2-广播\" data-toc-modified-id=\"1.2.2-广播-1.2.2\">1.2.2 广播</a></span></li><li><span><a href=\"#1.2.3-张量点积\" data-toc-modified-id=\"1.2.3-张量点积-1.2.3\">1.2.3 张量点积</a></span></li></ul></li></ul></li><li><span><a href=\"#2.-BP(Back-Propagation)\" data-toc-modified-id=\"2.-BP(Back-Propagation)-2\">2. BP(Back Propagation)</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.1-数据假设\" data-toc-modified-id=\"2.1-数据假设-2.1\">2.1 数据假设</a></span></li><li><span><a href=\"#2.2-神经网络假设\" data-toc-modified-id=\"2.2-神经网络假设-2.2\">2.2 神经网络假设</a></span></li><li><span><a href=\"#2.3-神经网络运行(前馈)\" data-toc-modified-id=\"2.3-神经网络运行(前馈)-2.3\">2.3 神经网络运行(前馈)</a></span></li><li><span><a href=\"#2.4-神经网络更新参数（反向传播，反馈）\" data-toc-modified-id=\"2.4-神经网络更新参数（反向传播，反馈）-2.4\">2.4 神经网络更新参数（反向传播，反馈）</a></span></li><li><span><a href=\"#2.5-具体权重更新推导\" data-toc-modified-id=\"2.5-具体权重更新推导-2.5\">2.5 具体权重更新推导</a></span></li><li><span><a href=\"#2.6-BP算法流程\" data-toc-modified-id=\"2.6-BP算法流程-2.6\">2.6 BP算法流程</a></span></li><li><span><a href=\"#2.7-BP算法额外说明\" data-toc-modified-id=\"2.7-BP算法额外说明-2.7\">2.7 BP算法额外说明</a></span></li></ul></li><li><span><a href=\"#3.-优化算法\" data-toc-modified-id=\"3.-优化算法-3\">3. 优化算法</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.1-惯性保持\" data-toc-modified-id=\"3.1-惯性保持-3.1\">3.1 惯性保持</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.1.1-带动量的SGD\" data-toc-modified-id=\"3.1.1-带动量的SGD-3.1.1\">3.1.1 带动量的SGD</a></span></li><li><span><a href=\"#3.1.2-Nesterov-动量\" data-toc-modified-id=\"3.1.2-Nesterov-动量-3.1.2\">3.1.2 Nesterov 动量</a></span></li><li><span><a href=\"#3.1.3-momentum和NAG的比较\" data-toc-modified-id=\"3.1.3-momentum和NAG的比较-3.1.3\">3.1.3 momentum和NAG的比较</a></span></li></ul></li><li><span><a href=\"#3.2-自适应学习率\" data-toc-modified-id=\"3.2-自适应学习率-3.2\">3.2 自适应学习率</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.2.1-AdaGrad(2011)\" data-toc-modified-id=\"3.2.1-AdaGrad(2011)-3.2.1\">3.2.1 AdaGrad(2011)</a></span></li><li><span><a href=\"#3.2.2-RMSProp(2012)\" data-toc-modified-id=\"3.2.2-RMSProp(2012)-3.2.2\">3.2.2 RMSProp(2012)</a></span></li><li><span><a href=\"#3.2.3-AdaDelta(2012)\" data-toc-modified-id=\"3.2.3-AdaDelta(2012)-3.2.3\">3.2.3 AdaDelta(2012)</a></span></li><li><span><a href=\"#3.2.4-Adam(2014)\" data-toc-modified-id=\"3.2.4-Adam(2014)-3.2.4\">3.2.4 Adam(2014)</a></span></li></ul></li><li><span><a href=\"#3.3-算法可视化\" data-toc-modified-id=\"3.3-算法可视化-3.3\">3.3 算法可视化</a></span></li><li><span><a href=\"#3.4-优化算法的选择\" data-toc-modified-id=\"3.4-优化算法的选择-3.4\">3.4 优化算法的选择</a></span></li><li><span><a href=\"#3.5-相关阅读\" data-toc-modified-id=\"3.5-相关阅读-3.5\">3.5 相关阅读</a></span></li></ul></li><li><span><a href=\"#4.-激活函数\" data-toc-modified-id=\"4.-激活函数-4\">4. 激活函数</a></span><ul class=\"toc-item\"><li><span><a href=\"#4.1-激活函数的作用\" data-toc-modified-id=\"4.1-激活函数的作用-4.1\">4.1 激活函数的作用</a></span></li><li><span><a href=\"#4.2-神经网络的万能近似定理\" data-toc-modified-id=\"4.2-神经网络的万能近似定理-4.2\">4.2 神经网络的万能近似定理</a></span></li><li><span><a href=\"#4.3-激活函数的形象解释\" data-toc-modified-id=\"4.3-激活函数的形象解释-4.3\">4.3 激活函数的形象解释</a></span></li><li><span><a href=\"#4.4-常见的激活函数\" data-toc-modified-id=\"4.4-常见的激活函数-4.4\">4.4 常见的激活函数</a></span><ul class=\"toc-item\"><li><span><a href=\"#4.4.1-ReLU及其扩展\" data-toc-modified-id=\"4.4.1-ReLU及其扩展-4.4.1\">4.4.1 ReLU及其扩展</a></span></li><li><span><a href=\"#4.4.2-Sigmoid函数\" data-toc-modified-id=\"4.4.2-Sigmoid函数-4.4.2\">4.4.2 Sigmoid函数</a></span></li><li><span><a href=\"#4.4.3-tanh函数\" data-toc-modified-id=\"4.4.3-tanh函数-4.4.3\">4.4.3 tanh函数</a></span></li><li><span><a href=\"#4.4.4-softplus函数\" data-toc-modified-id=\"4.4.4-softplus函数-4.4.4\">4.4.4 softplus函数</a></span></li><li><span><a href=\"#4.4.5-ReLU和Sigmoid比较\" data-toc-modified-id=\"4.4.5-ReLU和Sigmoid比较-4.4.5\">4.4.5 ReLU和Sigmoid比较</a></span></li></ul></li></ul></li><li><span><a href=\"#5.-正则化\" data-toc-modified-id=\"5.-正则化-5\">5. 正则化</a></span><ul class=\"toc-item\"><li><span><a href=\"#5.1-批标准化(Batch-Normalization)\" data-toc-modified-id=\"5.1-批标准化(Batch-Normalization)-5.1\">5.1 批标准化(Batch Normalization)</a></span><ul class=\"toc-item\"><li><span><a href=\"#5.1.1-算法原理\" data-toc-modified-id=\"5.1.1-算法原理-5.1.1\">5.1.1 算法原理</a></span></li><li><span><a href=\"#5.1.2-单个样本计算(移动平均)\" data-toc-modified-id=\"5.1.2-单个样本计算(移动平均)-5.1.2\">5.1.2 单个样本计算(移动平均)</a></span></li><li><span><a href=\"#5.1.3-为什么训练时不采用移动平均\" data-toc-modified-id=\"5.1.3-为什么训练时不采用移动平均-5.1.3\">5.1.3 为什么训练时不采用移动平均</a></span></li><li><span><a href=\"#5.1.4-BN的作用\" data-toc-modified-id=\"5.1.4-BN的作用-5.1.4\">5.1.4 BN的作用</a></span></li><li><span><a href=\"#5.1.5-BN相关阅读\" data-toc-modified-id=\"5.1.5-BN相关阅读-5.1.5\">5.1.5 BN相关阅读</a></span></li></ul></li><li><span><a href=\"#5.2-L1/L2正则\" data-toc-modified-id=\"5.2-L1/L2正则-5.2\">5.2 L1/L2正则</a></span></li><li><span><a href=\"#5.3-Dropout\" data-toc-modified-id=\"5.3-Dropout-5.3\">5.3 Dropout</a></span><ul class=\"toc-item\"><li><span><a href=\"#5.3.1-训练时流程\" data-toc-modified-id=\"5.3.1-训练时流程-5.3.1\">5.3.1 训练时流程</a></span></li><li><span><a href=\"#5.3.2-预测时流程\" data-toc-modified-id=\"5.3.2-预测时流程-5.3.2\">5.3.2 预测时流程</a></span></li><li><span><a href=\"#5.3.3-dropout的作用\" data-toc-modified-id=\"5.3.3-dropout的作用-5.3.3\">5.3.3 dropout的作用</a></span></li></ul></li></ul></li><li><span><a href=\"#6.-References\" data-toc-modified-id=\"6.-References-6\">6. References</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Representation\n",
    "\n",
    "### 1.1 张量介绍\n",
    "\n",
    "一般来说，当前所有机器学习系统使用**张量**(tensor)作为数据结构，它是一个数据容器，包含的数据几乎总是数值类型。矩阵是二维张量，它是矩阵向任意维度的推广，张量的维度(dimension)叫做轴(axis)。\n",
    "\n",
    "- 标量(`0D`张量)   \n",
    "仅包含一个数字的张量叫做标量(scalar)，也称之为标量张量、零维张量\n",
    "\n",
    "- 向量(`1D`张量)\n",
    "数字组成的数组叫作向量(vector)或者一维张量，如下，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T11:37:04.152585Z",
     "start_time": "2019-04-04T11:37:04.143332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D tensor: [1 3 5 7]\n",
      "1D axis:  1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([1, 3, 5, 7])\n",
    "print(\"1D tensor:\", x)\n",
    "print(\"1D axis: \", x.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 矩阵(`2D`张量)\n",
    "向量组成的数组叫做矩阵(matrix)或者二维张量，如下，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T11:41:16.667646Z",
     "start_time": "2019-04-04T11:41:16.659098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D tensor: \n",
      " [[2 7 4]\n",
      " [1 7 2]]\n",
      "2D axis:  2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.random.randint(10, size=(2, 3))\n",
    "print(\"2D tensor: \\n\", x)\n",
    "print(\"2D axis: \", x.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T11:48:39.756484Z",
     "start_time": "2019-04-04T11:48:39.746052Z"
    }
   },
   "source": [
    "- `3D`张量\n",
    "将多个矩阵组成一个数组便可以得到一个3D张量，如下，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T11:43:13.677897Z",
     "start_time": "2019-04-04T11:43:13.663044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D tensor: \n",
      " [[[7 7 6 9 4]\n",
      "  [0 7 4 8 7]\n",
      "  [9 9 1 1 9]]\n",
      "\n",
      " [[4 2 1 5 7]\n",
      "  [0 0 8 3 4]\n",
      "  [1 2 5 9 4]]]\n",
      "3D axis:  3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.random.randint(10, size=(2, 3, 5))\n",
    "print(\"3D tensor: \\n\", x)\n",
    "print(\"3D axis: \", x.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以依次类推到更高维度的张量，现实中的数据张量，\n",
    "\n",
    "- 结构化数据   \n",
    "2D张量，形状(samples, features)\n",
    "\n",
    "- 序列数据   \n",
    "3D张量，形状(samples, timesteps, features)\n",
    "\n",
    "- 图像数据   \n",
    "4D张量，形状(samples, channels, height, width)\n",
    "\n",
    "- 视频数据   \n",
    "5D张量，形状(samples, frames, channels, height, width)\n",
    "\n",
    "张量的属性，\n",
    "\n",
    "- 轴的个数(阶)   \n",
    "nD张量有n个轴\n",
    "\n",
    "- 形状   \n",
    "nD张量的形状为长度为n向量，比如3D张量的形状可以为(1, 2, 4), (2, 5, 7)等等\n",
    "\n",
    "- 数据类型   \n",
    "绝大多数情况下张量的类型为数值类型，很少为字符串类型，因为张量存储在预先分配的连续内存中，但是字符串长度是可变的，无法用这种方式存储。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 张量计算\n",
    "\n",
    "#### 1.2.1 逐元素运算\n",
    "\n",
    "逐元素计算(element-wise)，独立的对张量中的每一个元素进行计算，完全可以实现并行\n",
    "\n",
    "#### 1.2.2 广播\n",
    "如果两个不同形状的张量进行相加，较小的张量会被广播(broadcast)，来匹配较大张量的形状，通常广播包含两个小步骤，\n",
    "1）向较小的张量添加轴（广播轴），使其ndim和大的张量相同\n",
    "2）将较小的张量沿着新的轴重复"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T12:24:10.319689Z",
     "start_time": "2019-04-04T12:24:10.295262Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor operation broadcast:\n",
      "x1:\n",
      " [[[1 0 8 9 6 1]\n",
      "  [5 7 5 4 2 7]\n",
      "  [8 5 1 8 4 8]\n",
      "  [8 7 8 7 8 1]]\n",
      "\n",
      " [[2 3 7 9 3 0]\n",
      "  [2 9 9 5 5 9]\n",
      "  [0 9 0 1 7 5]\n",
      "  [0 5 5 6 5 0]]]\n",
      "x2:\n",
      " [[9 4 5 7 9 0]\n",
      " [0 5 7 0 8 8]\n",
      " [6 8 1 1 5 5]\n",
      " [9 9 6 1 7 1]]\n",
      "x1 + x2 = \n",
      "\n",
      "[[[10  4 13 16 15  1]\n",
      "  [ 5 12 12  4 10 15]\n",
      "  [14 13  2  9  9 13]\n",
      "  [17 16 14  8 15  2]]\n",
      "\n",
      " [[11  7 12 16 12  0]\n",
      "  [ 2 14 16  5 13 17]\n",
      "  [ 6 17  1  2 12 10]\n",
      "  [ 9 14 11  7 12  1]]]\n",
      "x1 shape (2, 4, 6) x1 ndim 3\n",
      "x2 shape (4, 6) x2 ndim 2\n",
      "x shape (2, 4, 6) x ndim 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "x1 = np.random.randint(10, size=(2, 4, 6))\n",
    "x2 = np.random.randint(10, size=(4, 6))\n",
    "x = x1+x2\n",
    "\n",
    "print(\"tensor operation broadcast:\")\n",
    "print(\"x1:\\n\", x1)\n",
    "print(\"x2:\\n\", x2)\n",
    "\n",
    "print(\"x1 + x2 = \\n\")\n",
    "print(x)\n",
    "\n",
    "print(\"x1 shape {} x1 ndim {}\".format(x1.shape, x1.ndim))\n",
    "print(\"x2 shape {} x2 ndim {}\".format(x2.shape, x2.ndim))\n",
    "print(\"x shape {} x ndim {}\".format(x.shape, x.ndim))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 张量点积\n",
    "一般在Numpy、Keras、Theano和Tensorflow中，使用`*`实现逐元素乘积，在Numpy和Keras中，使用`dot`来实现点积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T12:28:38.322002Z",
     "start_time": "2019-04-04T12:28:38.294003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor operation product:\n",
      "x1:\n",
      " [[[9 2 8 6 4 0]\n",
      "  [6 9 5 1 0 7]\n",
      "  [0 1 9 4 0 4]\n",
      "  [5 2 2 5 2 3]]\n",
      "\n",
      " [[5 5 7 2 2 0]\n",
      "  [8 6 4 1 5 1]\n",
      "  [9 8 9 4 7 5]\n",
      "  [3 7 7 3 9 9]]]\n",
      "x2:\n",
      " [[9 6]\n",
      " [3 6]\n",
      " [3 4]\n",
      " [3 5]\n",
      " [6 6]\n",
      " [5 0]]\n",
      "x1 + x2 = \n",
      "\n",
      "[[[153 152]\n",
      "  [134 115]\n",
      "  [ 62  62]\n",
      "  [ 99  87]]\n",
      "\n",
      " [[ 99 110]\n",
      "  [140 135]\n",
      "  [211 200]\n",
      "  [177 157]]]\n",
      "x1 shape (2, 4, 6) x1 ndim 3\n",
      "x2 shape (6, 2) x2 ndim 2\n",
      "x shape (2, 4, 2) x ndim 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "x1 = np.random.randint(10, size=(2, 4, 6))\n",
    "x2 = np.random.randint(10, size=(6, 2))\n",
    "\n",
    "x = np.dot(x1, x2)\n",
    "\n",
    "print(\"tensor operation product:\")\n",
    "print(\"x1:\\n\", x1)\n",
    "print(\"x2:\\n\", x2)\n",
    "\n",
    "print(\"x1 + x2 = \\n\")\n",
    "print(x)\n",
    "\n",
    "print(\"x1 shape {} x1 ndim {}\".format(x1.shape, x1.ndim))\n",
    "print(\"x2 shape {} x2 ndim {}\".format(x2.shape, x2.ndim))\n",
    "print(\"x shape {} x ndim {}\".format(x.shape, x.ndim))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. BP(Back Propagation)\n",
    "在神经网络训练时，往往基于反向传播算法，通过优化算法来优化网络权重。\n",
    "通常说”BP网络“时，一般是指用BP算法训练的多层前馈神经网络。\n",
    "\n",
    "### 2.1 数据假设   \n",
    "对于给定的数据集$D=\\{(\\vec{x_1}, \\vec{y_1}), \\ldots, (\\vec{x_m}, \\vec{y_m})\\}, \\vec{x_i} \\in R^d, \\vec{y_i} \\in R^l$，相当于数据集包含$m$个样本，每个样本有$d$个属性和对应$l$个标签。   \n",
    "\n",
    "### 2.2 神经网络假设   \n",
    "假设网络结构为三层，分别为输入层、隐含层和输出层，其分别对应$d$个输入神经元、$q$个隐含神经元和$l$个输出神经元。假设输入层至隐含层的连接权重为$v_{ih}$，隐含层至输出层的连接权重为$w_{hj}$，隐含层的神经元阈值为$\\gamma_{h}$，输出层的神经元阈值为$\\theta_{j}$，显然$i \\in {1, 2, \\cdots, d}, h \\in {1, 2, \\cdots, q}, j \\in {1, 2, \\cdots, l}$    \n",
    "> Note：此处日后有时间可以加一张图，来绘制一下网络结构\n",
    "\n",
    "\n",
    "### 2.3 神经网络运行(前馈)      \n",
    "对于某一个训练样本，$(\\vec{x_k}, \\vec{y_k})$，首先经过加权进入至隐含层，$\\alpha_{h}=\\sum_{i=1}^d v_{ih} \\cdot x_i$，隐含层具体取值为$b_h = f(\\alpha_h - \\gamma_h)$，然后数据由隐含层进入至输出层，$\\beta_j=\\sum_{h=1}^q w_{hj} \\cdot b_h$，在输出层的具体输出为$\\hat{y_j}=f(\\beta_j-\\theta_j)$，其中函数$f$为sigmoid函数\n",
    "\n",
    "### 2.4 神经网络更新参数（反向传播，反馈）   \n",
    "假设我们采用的损失函数为均方损失，那么对于训练样本$(\\vec{x_k}, \\vec{y_k})$，其对应的损失则为，   \n",
    "$$L_k=\\frac{1}{2}\\sum_{j=1}^l(y_j-\\hat{y_j})^2$$\n",
    "上述神经网络中共对应$(d+l+1)q+l$个参数，其中输入层值隐含层权重数量为$d \\cdot q$，隐含层阈值数量为$q$，隐含层至输出层权重的数量为$q \\cdot l$，输入层阈值数量为$l$.    \n",
    "BP算法是基于梯度下降策略来对权重进行更新调整，大致形式为，\n",
    "$v = v - \\eta \\frac{\\partial L}{\\partial v}$\n",
    "\n",
    "### 2.5 具体权重更新推导 \n",
    "- 参数$w_{hj}$的更新   \n",
    "基于梯度下降策略，其大致形式为$w_{hj}=w_{hj}-\\eta \\frac{\\partial L_k}{\\partial w_{hj}}$，依据链式法则，有如下， \n",
    "$$\\frac{\\partial L_k}{w_{hj}} = \\frac{\\partial L_k}{\\partial \\hat{y_{j}}} \\cdot \\frac{\\partial \\hat{y_{j}}}{\\partial \\beta_{j}} \\cdot \\frac{\\partial \\beta_{j}}{\\partial w_{hj}}$$\n",
    "其中，\n",
    "$\\frac{\\partial L_k}{\\partial \\hat{y_j}} = \\hat{y_j}-y_j$, \n",
    "$\\frac{\\partial \\hat{y_j}}{\\partial \\beta_j} = \\hat{y_j}(1-\\hat{y_j})$, \n",
    "$\\frac{\\beta_j}{\\partial w_{hj}} = b_h$\n",
    "所以，   \n",
    "$$\\frac{\\partial L_k}{w_{hj}} = (\\hat{y_j}-y_j) \\cdot (\\hat{y_j}(1-\\hat{y_j})) \\cdot b_h$$\n",
    "\n",
    "- 参数$\\theta_j$的更新   \n",
    "形式为$\\theta_j = \\theta_j - \\eta \\frac{\\partial L_k}{\\partial \\theta_j}$，其中， \n",
    "$\\frac{\\partial L_k}{\\partial \\theta_j} = \\frac{\\partial L_k}{\\partial \\hat{y_{j}}} \\cdot \\frac{\\partial \\hat{y_j}}{\\partial \\theta_j}=(\\hat{y_j} - y_j) \\cdot (\\hat{y_j}(\\hat{y_j}-1))$\n",
    "\n",
    "- 参数$v_{ih}$的更新   \n",
    "形式为$v_{ih} = v_{ih} - \\eta \\frac{\\partial L_k}{\\partial v_{ih}}$，依据链式法则，有如下，\n",
    "$$\\frac{\\partial L_k}{\\partial v_{ih}} = \\frac{\\partial \\alpha_{h}}{\\partial v_{ih}} \\cdot \\frac{\\partial b_h}{\\partial \\alpha_h} \\cdot \\sum_{j=1}^{l}\\frac{\\partial \\beta_j}{\\partial b_h}\\frac{\\partial \\hat{y_j}}{\\partial \\beta_j} \\frac{\\partial L_k}{\\partial \\hat{y_j}}$$ \n",
    "其中，\n",
    "$\\frac{\\partial \\alpha_{h}}{\\partial v_{ih}} = x_i$, \n",
    "$\\frac{\\partial b_h}{\\partial \\alpha_h} = b_h(1-b_h)$, \n",
    "$\\frac{\\partial \\beta_j}{\\partial b_h} = w_{hj}$,\n",
    "$\\frac{\\partial \\hat{y_j}}{\\partial \\beta_j} = \\hat{y_j}(1-\\hat{y_j})$,\n",
    "$\\frac{\\partial L_k}{\\partial \\hat{y_j}} = \\hat{y_j}-y_j$\n",
    "所以，   \n",
    "$$\\frac{\\partial L_k}{\\partial v_{ih}} = x_i \\cdot b_h(1-b_h) \\cdot \\sum_{j=1}^{l}w_{hj}\\hat{y_j}(1-\\hat{y_j})(\\hat{y_j}-y_j)$$\n",
    "\n",
    "- 参数$\\gamma_h$的更新   \n",
    "形式为$\\gamma_h = \\gamma_h - \\eta \\frac{\\partial L_k}{\\partial \\gamma_h}$，依据链式法则， \n",
    "$$\\frac{\\partial L_k}{\\partial \\gamma_h} = \\frac{\\partial b_h}{\\partial \\gamma_h} \\cdot \\sum_{j=1}^{l}\\frac{\\partial \\beta_j}{\\partial b_h}\\frac{\\partial \\hat{y_j}}{\\partial \\beta_j} \\frac{\\partial L_k}{\\partial \\hat{y_j}}$$，\n",
    "根据上面**参数$v_{ih}$的更新**，\n",
    "$$\\frac{\\partial L_k}{\\partial \\gamma_h} = b_h(b_h-1) \\cdot \\sum_{j=1}^{l}w_{hj}\\hat{y_j}(1-\\hat{y_j})(\\hat{y_j}-y_j)$$\n",
    "\n",
    "### 2.6 BP算法流程\n",
    "BP算法具体框架如下，  \n",
    "\n",
    "------\n",
    "\n",
    "**输入：**   \n",
    "$\\quad $ 训练集$ D=\\{ (\\vec{x_k}, \\vec{y_k})\\}_{k=1}^m, \\vec{x_k} \\in R_d, \\vec{y_k} \\in R_l$   \n",
    "$\\quad $ 学习率$\\eta$    \n",
    "$\\quad $ 对应的损失函数$L$   \n",
    "**过程：**    \n",
    "1.在$(0, 1)$范围内随机初始化网络中所有的连接权值和阈值    \n",
    "2.**Repeat**  \n",
    "3.$\\quad $ **for all $(\\vec{x_k}, \\vec{y_k}) \\in D:$**   \n",
    "4.$\\qquad $根据**2.2.3 神经网络运行（前馈）**，求得对应输入$\\vec{x_k}$的输出$\\hat{y_k}$;   \n",
    "5.$\\qquad $分别求参数$w_{hj},\\theta_j,v_{ih}, \\gamma_h$对应的梯度值$\\frac{\\partial L_k}{\\partial w_{hj}}, \\frac{\\partial L_k}{\\partial \\theta_{j}}, \\frac{\\partial L_k}{\\partial v_{ih}}, \\frac{\\partial L_k}{\\partial \\gamma_h}$   \n",
    "6.$\\qquad $按照梯度下降的方式，更新参数$w_{hj},\\theta_j,v_{ih}, \\gamma_h$   \n",
    "7.$\\quad $ **end for**   \n",
    "8.**until**达到停止条件   \n",
    "**输出：**    \n",
    "连接权重和阈值，即$w_{hj},\\theta_j,v_{ih}, \\gamma_h$\n",
    "\n",
    "------\n",
    "\n",
    "### 2.7 BP算法额外说明\n",
    "上述**2.2.6 BP算法流程**中，每次针对一个训练样本更新权重和阈值，该过程也被称之为**标准BP算法**。需要注意的是，BP算法的目标是最小化训练集的损失，\n",
    "$$L = \\frac{1}{m}\\sum_{k=1}^{m}L_k$$\n",
    "如果上面基于此来推导连接权重和阈值，这样就称之为**累计误差逆传播算法**，两者之间的区别类似于**随机梯度下降(SGD)**和**标准梯度下降**。   \n",
    "为了达到相同的损失极小点，标准BP算法往往需要更多次数的迭代，累计BP算法需要读取整个训练集一遍后才对参数进行更新，其参数更新频率更新要低的多。  \n",
    "在大多数任务中，累计损失下降到一定程度后，进一步下降会非常缓慢，这时标准BP往往会获得较好的解。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 优化算法\n",
    "在目录`../../optimization_learning`中目前有一部分传统的优化算法，目前有**GradientDescent**，**CoordinateDescent**和**NewtonMethod**，本部分所介绍的优化算法，主要是深度学习中经常用到的，比如Adagrad，RMSProp，Adam等\n",
    "\n",
    "在**GradientDescent.ipynb**中提到随机梯度下降可能遇到”峡谷“和”鞍点“两种情况，SGD的改进遵循两个方向，分别是**惯性保持**和**环境感知**。\n",
    "\n",
    "### 3.1 惯性保持   \n",
    "惯性保持指的是在SGD中加入动量  \n",
    "\n",
    "#### 3.1.1 带动量的SGD  \n",
    "- 作用   \n",
    "引入动量（Momentum）方法一方面是为了解决“峡谷”和“鞍点”问题；一方面也可以用于SGD加速，特别是针对高曲率、小幅但是方向一致的梯度。   \n",
    "  - ”峡谷“和”鞍点“：如果把原始的 SGD 想象成一个纸团在重力作用向下滚动，由于质量小受到山壁弹力的干扰大，导致来回震荡；或者在鞍点处因为质量小速度很快减为 0，导致无法离开这块平地。   \n",
    "  - 动量：动量方法相当于把纸团换成了铁球；不容易受到外力的干扰，轨迹更加稳定；同时因为在鞍点处因为惯性的作用，更有可能离开平地。   \n",
    "  - 动量方法以一种廉价的方式模拟了二阶梯度（牛顿法）   \n",
    "  ![](../../../pics/峡谷_动量解决.png)\n",
    "  \n",
    "  \n",
    "- 算法描述   \n",
    "![](../../../pics/带动量SGD.png)\n",
    "从形式上看，动量算法引入了变量$v$充当速度角色，代表参数在参数空间移动的方向和速率，速度$v$累积了梯度元素$g$，相对于$\\epsilon, \\alpha$越大，之前的梯度对现在的方向影响也越大。   \n",
    "在SGD中，步长是梯度范数乘以学习率。现在，步长取决于**梯度序列的大小和排列**。当许多连续的梯度指向相同的方向时，步长最大。   \n",
    "如果动量算法总是观测到梯度$g$，那么它回在方向$-g$上不停地加速，知道达到最终速度，其中步长大小为，\n",
    "$$v \\leftarrow \\alpha v - \\epsilon g \\Longrightarrow v \\leftarrow \\frac{-\\epsilon g}{1-\\alpha}$$\n",
    "\n",
    "- 实践中，$\\alpha$的取值为0.5,0.9和0.99，分别对应的步长的2倍、10倍和100倍。   \n",
    "- 类似于下面所讲的自适应学习率，$\\alpha$也可以使用某种策略进行**自适应调整**；一般初始值是一个较小的值，随后慢慢变大。\n",
    "\n",
    "#### 3.1.2 Nesterov 动量\n",
    "Nesterov动量和标准动量之间的区别体现在梯度的计算上，Nesterov动量中，梯度计算在施加当前速度之后。   \n",
    "Nesterov动量可以解释为往标准动量方法中添加了一个**校正因子**。 \n",
    "Nesterov动量的直观理解：  \n",
    "> 动量法每下降一步都是由前面下降方向的一个累积和当前点的梯度方向组合而成。于是一位大神（Nesterov）就开始思考，既然每一步都要将两个梯度方向（历史梯度、当前梯度）做一个合并再下降，那为什么不先按照历史梯度往前走那么一小步，按照前面一小步位置的“超前梯度”来做梯度合并呢？如此一来，小球就可以先不管三七二十一先往前走一步，在靠前一点的位置看到梯度，然后按照那个位置再来修正这一步的梯度方向。如此一来，有了超前的眼光，小球就会更加”聪明“, 这种方法被命名为Nesterov accelerated gradient 简称 NAG。 --[NAG](https://blog.csdn.net/tsyccnh/article/details/76673073)\n",
    "\n",
    "具体算法流程如下， \n",
    "![](../../../pics/Nesterov动量.png)\n",
    "在凸批量梯度的情况下，Nesterov动量可以将额外无查收敛率从$O(1/k)$（k步后）改进到$O(1/k^2)$，在随机梯度的情况下，Nestov动量并没有改进收敛率。\n",
    "\n",
    "#### 3.1.3 momentum和NAG的比较    \n",
    "\n",
    "- momentum（标准动量）示意图    \n",
    "![](../../../pics/标准动量示意图.jpeg)\n",
    "\n",
    "- NAG（nesterov动量）示意图   \n",
    "![](../../../pics/nesterov动量示意图.jpeg)  \n",
    "\n",
    "具体实验比较，参考博文[NAG&momentum](https://blog.csdn.net/tsyccnh/article/details/76673073)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 自适应学习率 \n",
    "\n",
    "#### 3.2.1 AdaGrad(2011)  \n",
    "该算法的思想是独立地适应所有模型参数的学习率，缩放每个参数反比于其所有梯度 历史平方值总和的平方根。   \n",
    "具有损失最大偏导的参数相应地有一个快速下降的学习率，而具有小偏导数的参数在学习率上有相对较小的学习率的下降，净效果是在参数空间中更为平缓的倾斜方向会取得更大的进步。  \n",
    "- 算法描述   \n",
    "![](../../../pics/AdaGrad算法描述.png)\n",
    "\n",
    "- 算法优缺点   \n",
    " - 优点   \n",
    "   - 可以不用学习率适应参数，对于出现次数较少的特征采用较小的学习率，反之采用较大的学习率。因此可以处理稀疏数据\n",
    "   - 可以提高SGD的鲁棒性，有人用来训练glove（低频词需要较大的学习率，高频词需要较小的学习率）\n",
    " - 缺点   \n",
    "   - 训练深度学习神经网络时，训练开始时积累梯度平方会导致有效学习率过早和过量的减小  \n",
    "   - 学习率是单调递减的，训练后期学习率过小会导致训练困难，甚至提前结束  \n",
    "  \n",
    " 下面算法**AdaDelta**和**RMSProp**都是为解决**AdaGrad**的学习率过度衰减而产生的。\n",
    " \n",
    "#### 3.2.2 RMSProp(2012)\n",
    "RMSProp改变AdaGrad的梯度累积为**指数加权的移动平均**。  \n",
    "AdaGrad旨在应用于凸问题时快速收敛，当应用于非凸函数训练神经网络时，学习轨迹可能穿过了很多不同的结构，最终到达一个局部是凸的区域，由于AdaGrad根据整个平方梯度的整个历史收缩学习率，可能使得学习率在到达这样的凸结构之前就变得很小。    \n",
    "RMSProp使用指数衰减平均来丢弃遥远过去的历史，使其能够在找到凸状结构后快速收敛，相当于初始化于有该凸结构的AdaGrad算法。  \n",
    "\n",
    "- 算法描述   \n",
    "![](../../../pics/RMSProp算法描述.png)\n",
    "> Note: RMSProp建议初始值为：$\\epsilon=1e-3$，衰减率为$\\rho=0.9$\n",
    "\n",
    "- 带Nesterov动量的RMSProp\n",
    "![](../../../pics/带Nesterov动量RMSProp算法描述.png)\n",
    "\n",
    "#### 3.2.3 AdaDelta(2012)\n",
    "- AdaDelta 和 RMSProp 是独立发现的，AdaDelta 的前半部分与 RMSProp 完全一致   \n",
    "- AdaDelta 进一步解决了 AdaGrad 需要设置一个全局学习率的问题   \n",
    "\n",
    "- 算法描述   \n",
    "\n",
    "---\n",
    "\n",
    "**Require:** 衰减速率$\\rho$   \n",
    "**Require:** 初始参数$\\boldsymbol{\\theta}$   \n",
    "**Require:** 小常数$\\sigma$   \n",
    "$\\quad$ 初始化累计变量$\\boldsymbol{r}=0, \\boldsymbol{s}=0$   \n",
    "$\\quad$ **while**没有达到停止条件 **do**   \n",
    "$\\qquad$ 从训练集中采样包含$m$个样本$\\{\\boldsymbol{x^{(1)}}, \\cdots, \\boldsymbol{x^{(m)}}\\}$，对应目标为$\\boldsymbol{y^{(i)}}$    \n",
    "$\\qquad$ 计算梯度$\\boldsymbol{g} \\leftarrow \\frac{1}{m}\\nabla_{\\boldsymbol{\\theta}}\\sum_{i}L(f(\\boldsymbol{x^{(i)}});\\boldsymbol{\\theta}, \\boldsymbol{y^{(i)}})$    \n",
    "$\\qquad$ 累计平方梯度：$\\boldsymbol{r_t} \\leftarrow \\rho \\boldsymbol{r_{t-1}}+(1-\\rho)\\boldsymbol{g} \\bigodot \\boldsymbol{g}$\n",
    "\n",
    "> 以上部分和RMSProp一样\n",
    "\n",
    "$\\qquad$ 计算参数更新：$\\boldsymbol{\\Delta \\theta}=-\\frac{\\sqrt{\\boldsymbol{s_{t-1}}+\\sigma}}{\\sqrt{\\boldsymbol{r}+\\sigma}}$   \n",
    "$\\qquad$ 应用更新： $\\boldsymbol{\\theta} \\leftarrow \\boldsymbol{\\theta} + \\boldsymbol{\\Delta \\theta}$   \n",
    "$\\qquad$ 累计参数平方：$\\boldsymbol{s_t} \\leftarrow \\rho \\boldsymbol{s_{t-1}}+(1-\\rho)\\boldsymbol{\\Delta \\theta} \\bigodot \\boldsymbol{\\Delta \\theta}$   \n",
    "$\\quad$ **end while**\n",
    "\n",
    "---\n",
    "\n",
    "在AdaDelta算法中，不需要设置默认的学习率，相当于学习率为$\\sqrt{\\boldsymbol{s_{t-1}}+\\sigma}$\n",
    "\n",
    "- 缺点   \n",
    "但是到训练后期，进入局部最小值雷区之后，AdaDelta就会反复在局部最小值附近抖动。\n",
    "\n",
    "#### 3.2.4 Adam(2014)\n",
    "Adam 在 RMSProp 方法的基础上更进一步：\n",
    "- 加入了**历史梯度平方的指数衰减平均**   \n",
    "- 保留了**历史梯度的指数衰减平均**   \n",
    "\n",
    "- 算法描述  \n",
    "![](../../../pics/Adam算法描述.png)\n",
    "\n",
    "> 偏差修正： \n",
    "> 注意到，s 和 r 需要初始化为 0；且 ρ1 和 ρ2 推荐的初始值都很接近 1（0.9 和 0.999）\n",
    "> 这将导致在训练初期 s 和 r 都很小（偏向于 0），从而训练缓慢。\n",
    "> 因此，Adam 通过修正偏差来抵消这个倾向。\n",
    "\n",
    "- Adam的其它变种  \n",
    "  - AdaMax  \n",
    "    - Adam 的一个变种，对梯度平方的处理由指数衰减平均改为指数衰减求最大值\n",
    "  - Nadam  \n",
    "    - Nesterov 动量版本的 Adam\n",
    "  \n",
    "\n",
    " ### 3.3 算法可视化  \n",
    " \n",
    "在图(a)中，我们看到不同算法在损失曲面的等高线上走的不同路线。所有的算法都是从同一个点出发并选择不同路径到达最优点。其中，Adagrad，Adadelta和RMSprop能够立即转移到正确的移动方向上并以类似的速度收敛；而动量法和NAG会导致偏离，想像一下球从山上滚下的画面。然而，NAG能够在偏离之后快速修正其路线，因为NAG通过对最优点的预见增强其响应能力。   \n",
    "在图(b)中，SGD，动量法和NAG在鞍点处很难打破对称性，尽管后面两个算法最终设法逃离了鞍点。而Adagrad，RMSprop和Adadelta能够快速想着梯度为负的方向移动，其中Adadelta走在最前面。\n",
    "\n",
    "<div style=\"float:left;border:solid 1px 000;margin:2px;text-align:center\"><img src=\"../../../pics/算法等高线可视化.gif\"  width=\"400\" height=\"350\" >\n",
    " (a)损失曲面等高线优化算法可视化</div>\n",
    "\n",
    "<div style=\"float:right;border:solid 1px 000;margin:2px;text-align:center\"><img src=\"../../../pics/算法鞍点可视化.gif\" width=\"400\" height=\"350\" >\n",
    "(b)鞍点优化算法可视化</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 优化算法的选择  \n",
    "如果输入数据是稀疏的，选择任一**自适应学习率算法**可能会得到最好的结果。选用这类算法的另一个好处是无需调整学习率，选用默认值就可能达到最好的结果。    \n",
    "\n",
    "总的来说，RMSprop是Adagrad的扩展形式，用于处理在Adagrad中急速递减的学习率。RMSprop与Adadelta相同，所不同的是Adadelta在更新规则中不需要设置全局学习率（使用参数的均方根进行更新）。最后，Adam是将偏差校正和动量加入到RMSprop中。在这样的情况下，RMSprop、Adadelta和Adam是很相似的算法并且在相似的环境中性能都不错。Kingma等人指出在优化后期由于梯度变得越来越稀疏，偏差校正能够帮助Adam微弱地胜过RMSprop。综合看来，Adam可能是最佳的选择。\n",
    "  \n",
    "有趣的是，最近许多论文中采用不带动量的SGD和一种简单的学习率的退火策略。已表明，通常SGD能够找到最小值点，但是比其他优化的SGD花费更多的时间，与其他算法相比，SGD更加依赖鲁棒的初始化和退火策略，同时，SGD可能会陷入鞍点，而不是局部极小值点。因此，如果你关心的是快速收敛和训练一个深层的或者复杂的神经网络，你应该选择一个**自适应学习率**的方法。\n",
    "\n",
    "### 3.5 相关阅读   \n",
    "- [梯度下降优化算法综述](https://blog.csdn.net/google19890102/article/details/69942970)\n",
    "- [优化算法理论+代码实现+深度学习知识](http://zh.gluon.ai/chapter_optimization/index.html)\n",
    "\n",
    "## 4. 激活函数\n",
    "在神经网络中，激活函数定义了一个神经元的输出，它将神经元的输入值映射到一个范围，比如说(0, 1)或者(-1, 1)等等，这取决于不同的激活函数。\n",
    "\n",
    "### 4.1 激活函数的作用\n",
    "使用激活函数的目的是为了在网络中添加非线性元素，以此来增加网络的表示能力。假如不添加非线性元素，那么无论网络有多少层，其整体也是线性的，这样的网络显然表示能力较弱。\n",
    "\n",
    "### 4.2 神经网络的万能近似定理 \n",
    "神经网络的万能近似定理认为主要神经网络具有至少一个非线性隐藏层，那么只要给予网络足够数量的隐藏单元，它就可以以任意的精度来近似**任何从一个有限维空间到另一个有限维空间的函数**\n",
    "\n",
    "### 4.3 激活函数的形象解释\n",
    "参考知乎链接，[激活函数的形象解释](https://www.zhihu.com/question/22334626)\n",
    "\n",
    "### 4.4 常见的激活函数 \n",
    "\n",
    "#### 4.4.1 ReLU及其扩展\n",
    "扩展公式为$g(z;\\alpha)=\\max(0,z)+\\alpha \\cdot \\min(0,z)$，   \n",
    "\n",
    "- 标准ReLU(Rectified Linear Units)     \n",
    "当$\\alpha=0$时，即为标准的ReLU公式，$\\rm{ReLu}(z) = max(0, z)$    \n",
    "\n",
    "- 绝对值整流(absolute value rectification)   \n",
    "当$\\alpha=-1$时，即为绝对值整流函数，$g(z) = |z|$   \n",
    "\n",
    "- 渗漏整流线性单元（Leaky ReLU, Maas et al., 2013）   \n",
    "此时$\\alpha$取一个固定值，比如0.01\n",
    "\n",
    "- 参数化整流线性单元（parametric ReLU, PReLU, He et al., 2015）   \n",
    "此时$\\alpha$是一个可以学习的参数\n",
    "\n",
    "\n",
    "#### 4.4.2 Sigmoid函数\n",
    "函数为$\\sigma(z) = \\frac{1}{1+e^{-z}}, z \\in R, \\sigma(z) \\in (0, 1)$\n",
    "\n",
    "#### 4.4.3 tanh函数\n",
    "函数为$\\tanh(z)=\\frac{\\sinh(z)}{\\cosh(z)}=\\frac{e^x-e^{-x}}{e^x+e^{-x}}, z \\in R, \\tanh(z) \\in (-1, 1)$\n",
    "\n",
    "#### 4.4.4 softplus函数\n",
    "函数为$g(z)=\\log(1+e^z)$，可以理解为函数ReLU的平滑版本，依据经验来看，其效果要差于ReLU\n",
    "\n",
    "下面**CELL**中绘制相应的函数图像。\n",
    "\n",
    "#### 4.4.5 ReLU和Sigmoid比较\n",
    "1. 避免梯度消失   \n",
    " - sigmoid函数在输入取绝对值非常大的正值或负值时会出现饱和现象——在图像上表现为变得很平，此时函数会对输入的微小变化不敏感——从而造成梯度消失；   \n",
    " - ReLU 的导数始终是一个常数——负半区为 0，正半区为 1——所以不会发生梯度消失现象   \n",
    "\n",
    "2. 减缓过拟合  \n",
    "ReLU 在负半区的输出为0，一旦神经元的激活值进入负半区，那么该激活值就不会产生梯度/不会被训练，造成了网络的稀疏性，这有助于减少参数的相互依赖，缓解过拟合问题的发生\n",
    "\n",
    "3. 加速计算  \n",
    "ReLU求导不涉及浮点数计算，故计算过程中，可以加速计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T11:53:26.774328Z",
     "start_time": "2019-04-11T11:53:25.626608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAHmCAYAAAA7qFm2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3XlcVPX+P/DXsIOIKM6AK4gKKIL7RiquoChlyu2apZlpmplmt8VbfrP6Zrfb8tMyr2ndb5pbmldJb4m45AqpmIoLi6AsosCwMzAw2/n9QU6i7DCcWV7Px2MecOacM5/358zMZ97nnM85H4kgCAKIiIiIqFVZiR0AERERkSViEkZEREQkAiZhRERERCJgEkZEREQkAiZhRERERCJgEkZEREQkAiZhRERERCJgEkZEREQkAiZh1Ciff/45tmzZUu9yERERuHnzpuEDamENrV9Tmep2IWosQRAwbtw4ZGRkGFW5X331FT744AP9tKm0aYZum5qrpKQEc+bMwZw5cxAcHIytW7cCEH+7GT2BTEpRUZHg4+MjDBgwQAgMDBTGjh0r7Nmzp0Hr5ufnCz4+PkJ2dvYj8y5cuCAMGjRI0Ol01Z6fO3eusHnzZv36o0aNEpRKZb1l/fzzz8LSpUsbFJexqKl+hYWFwpIlS4T+/fsLY8eOFQ4cONCsMkxxuxCZk1dffVXYtWuXIAjitWnbtm0TnnzyScHf31946623alwmOztbGD16dI1xNmR9sfz+++/CqlWrBI1GIwgC27z68EiYiUlISED79u1x6dIlXLlyBa+99hpWr16NgoKCBq/r7u5e47w+ffpAIpFUez4xMRF9+/YFAOzbtw/BwcFwcHCot6wJEybg3LlzyM3NbWDNxFdT/T744APY2tri7Nmz+PTTT/Hee+81a6/OFLcLkTlJSUmBr68vAPHaNJlMhiVLlmDmzJm1LnPq1CmMHj26xjgbsv7D1q9fj/Xr1zcrbrlcjqeffvqRh1wuBwDEx8fjxx9/xOrVq2FtbQ2AbV59mISZmMTERPj7++unhw0bBq1Wi5KSEv1ze/bsQVhYGAYPHowFCxYgPz8fwJ+JVk1u3LjxyLw7d+6gqKhI//ypU6cwdOhQ/fzly5dj4MCB+oevry+2b98OALC3t4e/vz/Onj3b7DqPHz8e3377LcLDwzFgwAC8/fbbyMvLw4IFCzBw4EDMmzcPxcXF+uU3b96MiRMnYuDAgQgLC8ORI0cAABkZGRg2bBiuX78OAMjJycHw4cNx7ty5GutXXl6O6OhoLF++HG3atMGQIUMwfvx4/PTTT/XGXNu2acntQmQMMjMzsWjRIgwfPhyDBw/G888/DwD48ccfsWTJEgCATqfDV199heDgYIwaNQrHjx9Hv3799N/bH3/8ES+88AJWr16NoUOHIjQ0FCkpKdi6dSvGjh2L4cOHIzo6GkDV6cbNmzdj3LhxGDJkCJYvX47S0lJ9PA+Xu2nTJowdOxajRo3Czz//jPT0dPTu3RuAeG1aSEgIJk6cCFdX11qXOXnyJIKDg2uMsyHrN0dtvyFSqRS7du165CGVSnHt2jXs2rUL77//PmxsbPSvxTavbkzCTMyNGzf0SVhJSQk+//xz+Pv7w9PTEwDw9ddf44cffsDGjRsRGxsLd3d3rFu3DkBVEubn51fj6z6c3N1f3sPDAx06dAAAJCcno0ePHvr5X3zxBS5duoRLly5h2bJl6NOnD6ZNm6af37NnTyQmJj5S1qJFizBkyJAaH4sWLaoxvujoaHz33Xc4fPgwfv31VyxcuBCvvfYazp07B51Oh23btumX7datG3bs2IGLFy9i6dKleOONN5Cbm4vu3bvj9ddfx+uvvw6lUom3334bM2bMwPDhw2usX1paGqysrKo95+fnh5SUlBpjfFBd26a27UJkit58802MGTMGMTExiImJwdKlSwEASUlJ+vZm/fr1iI2NxZ49e/DLL79g06ZNcHNzQ7t27fTLXrt2DZMnT8Zvv/0GHx8fLFy4EABw5MgRLFmyBBs3bgQArFu3DqdPn8bu3btx9uxZqFQqbNiwQR/Pg+Vu2LABv/76K3bs2IFDhw5h27ZtkEqlcHZ2BiBum1YXtVqNCxcuICgoqMY4Damu35C6LF68GLdv38b8+fPx4YcfVpvHNq92NvUvQsYkISEB0dHR2L59O8rKyjBq1Ch8++23kEgkyM/Px8aNGxEZGalPyiIiIvD+++8DqEq07u9ZPUitVuPmzZuPHAm7fv26/lQkAJSWlqJNmzaPrL9161ZERkZiy5Yt1fbM2rRpU+Mh6E2bNjW63s8++yw6duwIABgyZAg6dOigj23SpEmIjY3VLztlyhT9/2FhYdi0aRPi4+MxceJEPPXUUzh+/DieeuopANA37DXVr7y8HG3btq0WR9u2bVFWVtbguGvaNrVtFyJTlJmZCa1WC61WC3t7ewwePBhAVXszd+5cFBQUYMuWLYiMjNR3hXjsscdw9epV/WskJibixRdfxMiRIwFU/WirVCo899xzAAAfHx9oNBrk5eVh+/bt+OWXXyCTyQAAoaGh2Lt3b7XXul/u//3f/+Gnn35Cly5dAABjx45FfHy8flkx27S6xMXFwc/PT58s1hZnS6vvN6QuZ86cqXUe27zaMQkzISqVCrdu3cKhQ4fQvXt3HD58GO+88w5sbW0BALGxsVCr1fjLX/6iX0cQBPTt2xeVlZW4fft2taTqvtTUVABVDd+Drl69qm9QAcDFxeWRBGT79u3Yu3cvtm7divbt21ebV1ZWBhcXl+ZV+g/3EzCg6vD2g9MODg4oLy/XT0dGRuK7775DVlYWgKpkqrCwUD//qaeewksvvYT//d//hZ2dXa31c3JygkKhqBaHQqFocGNY27Zpye1CJLZPP/0UX3/9NTZs2IAJEybgzTffhKurq/6IVGxsLDw9PfU/6gBQXFwMHx8f/XRSUlK1H/rU1FSMHTtWP52SkgJvb2/ExcXBx8enWr/WoqIiSKXSaq91v1xvb290795dPy8vL69auWK2aXV58FRkbXE2xKJFi3Dx4kUAQGVlJQDor1ocPHjwI8ljXb8hzcE2r3ZMwkxIcnIy7Ozs0K1bNwBVe4BfffUVDh8+jIiICBQXF2PixIn48ssvH1k3Pj4etra2NR7Szs/Ph4ODQ7Xz+AUFBTh//jzeeOMN/XO+vr5IS0tDYGAgAGDnzp3YvXs3tm7dqj9l+aDU1FQ8/vjjjzy/YMECfcPwsMGDB+Pbb7+tZ0vULisrC6tWrcKWLVswcOBAWFtb44knntDPLysrw0cffYSIiAisX78eISEh+j3dh+vn5eUFrVaLtLQ0eHl5Aajay+7Vq1e9cdS1bWrbLkSmaOTIkRg5ciTy8/OxcOFC7N+/HyEhIdBoNOjWrRtOnTqlP2oFAFqtFqdOncIrr7wCoOo7q1arq7VNCQkJeOGFF/TTSUlJ6NOnDwoKCh45On3s2DGEhobqX+vBct3c3PTLqdVqHDt2DG+++ab+OWNt006ePImvvvqq1jgb6sEk636n/PvbvSZ1/YY0B9u82rFPmAlJSEhA7969q13BGBwcjOPHjwMA+vbti3Pnzuk7nisUChw9ehSCICAxMRE9e/aERqNBZWUlKisroVKpAFQd6lepVNizZw8qKipw+/Zt/O1vf8O4ceOq9SELDg7GhQsXAAC7d+/Gjh078N1339XYWKlUKly/fl3fp+FB3377rb7fxcOP5iRgAKBUKiGRSPQx/ec//6l2NeOaNWvg7++PNWvWYOzYsVi9enWN9QOqjoRNmjQJX375JcrLy3Hx4kUcO3asWlK3cuVKrFy5sloMdW2burYLkamJjo5GWloaBEFAWVkZSkpK4Ofnh8TERPj6+kIikaBnz564dOkS0tPToVAo8OGHHyIjI0N/RCoxMRE+Pj6wsqr6OVIoFLh7967+Csb7y/j5+SEgIACXL19GRkYGysrK8MUXXyAvL09/leCD5fbo0QMXL17E7du3UVpaivfeew93796tdiRMrDbtfjus0+mg1WpRWVkJjUYDoOr0rkqlqnZm4uG2qa71m6Ou35CmYptXNyZhJiQhIaFawwQAo0ePRkxMDCorKzFw4EC8/PLLeOWVV/RXBp4+fRoSiQSJiYm4fv06AgMD9Y+wsDAAVVe8rFu3Dtu2bcOwYcOwYMEC9O3bF//4xz+qlfXEE0/g5MmTqKiowKeffoqMjAxMmjRJfyVRZGSkftljx45h2LBhNd4Ow5B69eqF+fPnY9asWQgKCkJycjIGDRoEADh69ChOnz6tP+2xcuVK3LhxAwcOHHikfvetXr0aFRUVCAoKwt/+9je89957+iurAODevXv617+vrm0j1nYhMoSLFy/i2WefxaBBg7Bw4UJ9v677yRBQdaRs6tSpmD59OmbOnIk+ffrA0dER3t7eAP5MsO5LTExE9+7d4ejoCKDqCsf7fVYDAgKwePFizJ49G8HBwUhNTcXWrVv1yz5Y7mOPPYapU6di5syZiIiIQIcOHWBvb68/qg2I16Zt3LgRgYGB2Lx5Mw4cOIDAwEB9/9SHT0U+HGd96zdHXb8hTcU2rx5i3qSMTM/nn38ufPfdd/UuFxERISQlJRk+oBbW0PoJgiBUVlYKkydPFlQqVYNf31S3C1FL2blzp7Bo0SKxw9AztjZtwYIFwokTJx55vjFtkzFhm1c3iSA04zgjERFRHS5fvgypVIpOnTohNjYWr7/+OjZu3IgBAwaIHZpR+uabbzBnzpwG3UCWTB+TMCIiMpidO3fiiy++gFqthpeXF5YvX17jrXKILBGTMCIiIiIRsGM+ERERkQiYhBERERGJwKhv1lpYWAadrmFnS93cnJGfr6h/QRPHepoX1vNPVlYStG9v+KFZWlND2zB+DswL62leDNl+GXUSptMJDU7C7i9vCVhP88J6mq/GtGGWsn1YT/PCejYPT0cSERERiaBFkzCFQoFp06bhzp07AICYmBiEh4cjJCQEa9eubcmiiIiIiExaiyVhV65cwdNPP420tDQAQEVFBd5++23861//wi+//IJr167h5MmTLVUcERERkUlrsSRsz549WL16NWQyGQAgPj4enp6e6NatG2xsbBAeHo6oqKiWKo6IqNkePnr/oISEBMyYMQOhoaF45513WmSAZCKiB7VYErZmzRoMGTJEP52bmwupVKqflslkyMnJaaniiIia5eGj9w9744038O677+Lw4cMQBAF79uxp3QCJyOwZ7OpInU5XbeR1QRAaPRK7m5tzo5aXSts2anlTxXqaF3OtpyAISLlThJ5dXAEYXz3vH71/8803H5mXlZWFiooK/fiGM2bMwJdffonZs2e3dphEZkmnE6DW6qDR6qDRCtBoqv7X6gToBAGCULWMAAE6XVV7Uu15QYBO+PP5+//jj4sY71/L+OeYQMJD0w8vV33G/cm+Xu0hheEYLAnz8PCAXC7XT8vlcv2pyobKz1c0+LJQqbQt5PLSRr2+KWI9zYs51/Pk5SxsjUrC6nlDMSSgc731tLKSNHrHqznWrFlT67yHj+RLpdImHclvTH2MLUk1FNbT9AmCgJIyFdKzS1BUWln1UFSiWFEJhVINZYUGykoNyis0UFaq//irgUqjg1qjg0ajhanc2SJifG94e7oZ7P00WBLWv39/3L59G+np6ejatSv++9//YubMmYYqjoiMSJGiEnt+TYVfd1d0d2+9xKqltMSRfKDhO5LmnIw/iPU0LRUqDTJzFbiTq0BOoRK5hUrIi5TILVJCrdE9sry1lQSO9jZwtLeGg50NHOys4WRvgw5t7eFgZw1bG2vYWlvB2loCW2sr2NhYwcbaCjbWEthYW8HW2gpWVpKqhwSQSCSwkkggkVTtpEkk+GP6gfnVngck+PN7+vBX9v53WP+0BA9NV58vkQDu7Z0AwGA7kQZLwuzt7fHxxx/jlVdeQWVlJYKDgzF58mRDFUdERmTHkWSoNTo8N9mvScmL2B4+kp+Xl9foI/lEpqawtBI30gqQmF6IW/dKkJ1frj9dZ2djBWl7R8jaO6Kfdwd0cHFAN492gFYLlzZ2cGljhzYONib5fRdTiydhx48f1/8/cuRIHDhwoKWLICIj9nuyHBeT5JgZ7A33Dk5ih9MkXbp0gb29PS5evIjBgwfjp59+wpgxY8QOi6jF3ZErcO5GDi4myZFdUA4AcHa0Ra8u7TCsjzs8Pdqiu8wZrm3tYfVQgmUuR/zEZNTDFhGRaSmv0GB7dBK6Sp0ROqy72OE02sKFC7Fs2TIEBATgs88+w6pVq6BQKODv74+5c+eKHR5RiyirUOP0lXs4e+0esuRlsJJI0MfTFWP6d0Zfr/boKnN+JOEiw2ASRkQtZu/JVBSXqbB0RiBsrE1jVLQHj95/8803+v/9/Pywd+9eMUIiMojC0kr8EpuO01fvQqXWoWcXFzwzyQdD/WRwaWMndngWiUkYEbWI5MwinLiUhUlDusG7s4vY4RDRH8orNPj5tzQcjbsDnU7AiL7umDS0G7q7m+8VnKaCSRgRNZtao8PWqES4uTjgyTE9xA6HiP7we7Ic26OTUKxQYYS/O6aP9obU1VHssOgPTMKIqNl+jk3DvfxyrHiqPxzs2KwQiU1ZqcHWqEScT8hFN5kzXpkZiB6deITa2LC1JKJmyZIr8HNsOkb4uyPA203scIgs3p1cBTZEXoO8UIknR/fAlBGeJtNH09IwCSOiJtMJArZEJcLR3gazJvQWOxwiixefmo9/RV6Fo50N3nh6AHy7txc7JKoDkzAiarJff89CalYJXpjaBy5OvLqKSEyx17Lxf78koKvUGcv/EghXZ3uxQ6J6MAkjoiYpKKnAf06mwt+rPYL6eYgdDpFFO3XlLrYcSoRfd1e8MjMQjvb8eTcFfJeIqNEEQcD26GTodALmmOjQRETmIi4xF1ujEtHPuwNemREAWxtrsUOiBmJPPSJqtLgkOS6n5GH6aG/IeLk7kWgS0gqw+eB1eHd2wcvTmYCZGiZhRNQoZRVq7DiSDE+Ptpg0tKvY4RBZLHmREv+KvAb39k5YHtEf9nZMwEwNkzAiapQ9x1OgKFdj3mQ/WFuxCSESg1qjxb/2X4NOAF6ZGQBnR1uxQ6ImYAtKRA2WkF6I0/H3EDqsGzw9OOQJkVi2RycjPacUC8P7QtbeSexwqImYhBFRg6jUWmyNSoTU1QGPj+LQRERiuZiUi9Px9zB1pCcG9OoodjjUDEzCiKhBDsakIbdQiecm+8Heln1PiMSgUKqx7XASurs74wnuDJk8JmFEVK+MnFIc+i0DjwV4oK9XB7HDIbJYO48mo6xCgxem9uVQRGaA7yAR1UmnE7DlUCLaONrgr+M5NBGRWK6k5OG36zkID/JCN5mz2OFQC2ASRkR1OhqXibTsUsye6MMrsIhEotHq8MPxFHh0cELYSE+xw6EWwiSMiGqVV6TEvtO3ENjTDcP6yMQOh8hiHf89CzkF5Zg1oRdPQ5oRvpNEVCNBEPD94SRIIMGcEF8OTUQkEoVSjQNnbqNfjw4I8HYTOxxqQUzCiKhGv93IwbXbBZgR7A23dg5ih0NksQ6cuY0KlRZ/Hd+LO0NmhkkYET2itFyFXUdvwruzCyYM4tBERGIpLK3EictZGBXogS5SdsY3N0zCiOgRPxxLgbJSg3mT/WBlxT1vIrEc+i0dggBMHekldihkAEzCiKiaa7fzEXs9G1NGdEdXXgZPJJoiRSVOXrmLkf08IHV1FDscMgAmYUSkV6nS4vuoJLh3cEJ4kJfY4RBZtKhzGdBqBUzjLSnMFpMwItKLPHMLecUVmDfZF7Y2HJqISCwKpRonLmVhhL87B+g2Y0zCiAgAkJZdgugLmQge0Bm+3duLHQ6RRTt15S5UGh0mD+sudihkQAZPwn766SdMnToVU6dOxT//+U9DF0dETaDR6rDll0S4tLHDX8b2FDscIoum1elw/Pc76OPZnv0yzZxBkzClUok1a9Zg27Zt+OmnnxAXF4eYmBhDFklETXDkQiYychV4ZqIPnBwsY2iigwcPIiwsDCEhIdixY8cj869fv46ZM2fi8ccfx6JFi1BSUiJClGSJLiXnoaCkEhMH8/Yw5s6gSZhWq4VOp4NSqYRGo4FGo4G9vb0hiySiRsopLEfkmdsY2LsjBvtKxQ6nVeTk5GDt2rXYuXMnIiMjsXv3bqSkpFRbZs2aNVi2bBkOHDiAHj164N///rdI0ZKlORKXiY7tHNC/V0exQyEDszHkizs7O2P58uWYMmUKHB0dMXToUAwaNKjB67u5Ne4wrFTatrEhmiTW07yIWU9BEPDFf+Jha2OF5U8Pgls7w10Gb0zvZ0xMDEaMGAFXV1cAQGhoKKKiorB06VL9MjqdDmVlZQCqjuq3a9dOlFjJsqRnl+LmnWL8dXwv3qPPAhg0CUtMTMR//vMf/Prrr2jbti1ef/11/Pvf/8aCBQsatH5+vgI6ndCgZaXStpDLS5sTrklgPc2L2PU8E38PV27mYU6oL3QqjcFiaUg9rawkjd7xaqrc3FxIpX8e9ZPJZIiPj6+2zMqVKzF//nx89NFHcHR0xJ49expdTmPqY0xJqiGxnnXbe+oW7GysMH28D5wdjb9rAN/P5jFoEnbmzBmMHDkSbm5VA47OmDEDO3fubHASRkSGU1ymwu7jN9G7azsED+gsdjitSqfTVRuDTxCEatMVFRV45513sGXLFgQGBuK7777DW2+9hc2bNzeqnIbuSIqdjLcW1rNuKrUWv168g0G+UigVFVAqKgwQXcvh+/mnpu5EGrRPmJ+fH2JiYlBeXg5BEHD8+HEEBAQYskgiaqBdR5NRqdbiucl+sLKwQYE9PDwgl8v103K5HDKZTD+dnJwMe3t7BAYGAgD++te/4vz5860eJ1mW35PlUFZqMDqgk9ihUCsxaBI2atQoTJ06FTNmzMDjjz8OjUaDF1980ZBFElEDXEnJw/mEXEwb6YXOHduIHU6rCwoKQmxsLAoKCqBUKhEdHY0xY8bo53t6eiI7Oxu3bt0CABw7dow7kGRwp+PvoWM7B/h68j59lsKgpyMB4MUXX2TiRWRElJUabItOQueObRBmocOhuLu7Y8WKFZg7dy7UajUiIiIQGBiIhQsXYtmyZQgICMA//vEPvPrqqxAEAW5ubvjoo4/EDpvMWF6REgnphZg+qofFHZm2ZAZPwojIuOw/dQuFJZX4+5x+sLG23EEzwsPDER4eXu25b775Rv9/cHAwgoODWzssslBnrt6DBMBjPBVpUSy3BSayQKlZxTh28Q7GDeqCXl14ywUiYyAIAs7dyIGfZ3u4tXMQOxxqRUzCiCyERqvDlqhEuLa1x8xgDk1EZCwychTIKVRieF93sUOhVsYkjMhCHPotHVnyMswJ8YWjPXsiEBmLczdyYG0lwSAfyxixgv7EJIzIAtzLL8PBmDQM8ZNhQG8OhUJkLHSCgPOJOfDv0cEkbs5KLYtJGJGZ0wkCtkYlwc7GGs9M7C12OET0gNSsYhSUVGJ4H56KtERMwojM3Kkrd5GcWYSnxvdCO2d7scMhogecv5ELWxsrHqG2UEzCiMxYYWklfvw1FX7dXTE6kJe+ExkTnU7AhaRcBPZ0Yz9NC8UkjMiM7TySDLVGh+cm+1UbG5GIxJd6txglZSoM8ZXVvzCZJSZhRGbq92Q5LibL8cQoL7h3cBI7HCJ6yO/JclhbSRDY003sUEgkTMKIzFB5hQbbo5PQVeqM0GHdxQ6HiB4iCAIuJeehj1d7noq0YEzCiMzQ3pOpKC5T4fkwP4semojIWGXJy5BbpOS9wSwcW2ciM5OcWYQTl7IwaUg39OjkInY4RFSD32/KIQEwsBevirRkTMKIzIhao8PWqES4uThg+ugeYodDRLW4lJwH7y4uvG2MhWMSRmRGfo5Nw738csyd7AsHO/YzITJG+cUVSM8p5alIYhJGZC6y5Ar8HJuOEf7uCPDm1VZExupKah4AYABPRVo8JmFEZkAnCNgSlQhHexvMmsChiYiM2dXUfEhdHeDBW8dYPCZhRGbg19+zkJpVglkTesHFyU7scIioFmqNFgnphQj07sgbKBOTMCJTV1BSgb0nU+Hv1R4j/T3EDoeI6pCUWQSVRoeAnh3EDoWMAJMwIhMmCAK2RydDEATM5dBEREbvamoBbKyt4Nu9vdihkBFgEkZkwuKS5Lickofpo7whdXUUOxwiqkf8rXz4ebrC3tZa7FDICDAJIzJRZRVq7DiSDE+Ptpg0tKvY4RBRPXKLlMgpKOfVy6THJIzIRO05ngJFuRrzJvvB2opfZSJjdzU1HwAQyCSM/sCWm8gEJaQX4nT8PYQO6wZPj7Zih0NEDXD1Vj5k7R3hzltT0B+YhBGZGJVai61RiZC5OuLxURyaiMgUqDVaJKYX8lQkVcMkjMjEHDibhtxCJeZO9mXnXiITkZTxx60pmITRA5iEEZmQjJxSRJ3LwKiATujrxfsMEZmK+NR82NpYwa+7q9ihkBExeBJ2/PhxzJgxA1OmTMGHH35o6OKIzJZOJ2DLoUQ4O9rgqfG9xA6HiBrheloBfLu7wo5Hr+kBBk3CMjMzsXr1avzrX//CgQMHcOPGDZw8edKQRRKZraNxmUjLLsXTE33g7Ggrdjgm7+DBgwgLC0NISAh27NjxyPxbt25hzpw5ePzxx/HCCy+guLhYhCjJHBSWVuJefjn6evLoNVVn0CTsyJEjCAsLg4eHB2xtbbF27Vr079/fkEUSmaW8IiX2nb6FwJ5uGNZHJnY4Ji8nJwdr167Fzp07ERkZid27dyMlJUU/XxAEvPTSS1i4cCEOHDiAPn36YPPmzSJGTKbsRloBAKCvF++ST9XZGPLF09PTYWtri8WLF+PevXsYO3YsXn311Qav7+bm3KjypFLLuFSf9TQv9dVTEAR8tf8arK0kWP70IMjam+bl7cb0fsbExGDEiBFwda3qnxMaGoqoqCgsXboUAHD9+nU4OTlhzJgxAIDFixejpKREtHjJtN1IK4Szoy26yhr3m0bmz6BJmFarRVxcHLZt2wYnJye89NJL2L9/P2bMmNGg9fPzFdDphAYtK5W2hVxe2pxwTQLraV4aUs+3ivovAAAgAElEQVTY69n4PSkXsyf2hkSjNcnt0pB6WllJGr3j1VS5ubmQSqX6aZlMhvj4eP10RkYGOnbsiLfffhsJCQnw9vbG//zP/zS6nMbUx5iSVEOytHoKgoCkzCIM8JHCXeYiclQtz9Lez5Zm0CSsY8eOGDlyJDp0qDoPPnHiRMTHxzc4CSOydKXlKuw6ehPenV0wfhCHJmopOp2u2mDngiBUm9ZoNDh//jy2b9+OgIAArFu3Dh9//DE+/vjjRpXT0B1J7nSYlwfreS+/DAUlFejZyfzqbonvZ22auhNp0D5h48aNw5kzZ1BSUgKtVovTp0/D39/fkEUSmZUfjqVAWanBvMl+sLKS1L8CNYiHhwfkcrl+Wi6XQyb7s6+dVCqFp6cnAgICAADTpk2rdqSMqKFupBUCAPrwljJUA4MmYf3798eCBQswe/ZshIWFoXPnzpg5c6YhiyQyG9du5yP2ejamjPBkX5IWFhQUhNjYWBQUFECpVCI6Olrf/wsABg4ciIKCAiQmJgKoutUOdyCpKW6kFaBjOwfIXB3FDoWMkEFPRwJAREQEIiIiDF0MkVmpVGnxfVQSPDo4ITzIU+xwzI67uztWrFiBuXPnQq1WIyIiAoGBgVi4cCGWLVuGgIAAbNiwAatWrYJSqYSHhwc++eQTscMmE6PTCUjMKMJQP2n9C5NFMngSRkSNF3nmFvKKK/DW7IGwteHNHQ0hPDwc4eHh1Z775ptv9P/3798fe/fube2wyIykZZdCWalBH94fjGrBYYuIjExadgmiL2QieEBn+HbnfYWITFVCetX9wfp48ntMNWMSRmRENFodtvySCJc2dvjL2J5ih0NEzXAjrRBdpc5waWMndihkpJiEERmRIxcykZGrwLOTfODkwKGJiEyVSq3FzTvFvEs+1YlJGJGRyCksR+SZ2xjYuyMG+3JoIiJTlpJVDI1WxySM6sQkjMgICIKA76OSYGMtwbMhvmKHQ0TNdCOtENZWEvh0cxU7FDJiTMKIjMDZq9lISC9ExNheaN/WXuxwiKiZEtIL0KOzCxzseBMCqh2TMCKRFZepsPv4TfTu2g7BAzqLHQ4RNZOiXIW0e6Xoy6siqR5MwohEtutoMirVWsyb4gcrCYcmIjJ1V1PzIADoy6GKqB5MwohEdOFGNs4n5GLaSC90cmsjdjhE1AKu3MyDna0VvDu7iB0KGTkmYUQiUVZq8K//xKNLxzYIG8mhiYjMxeVkOXy7tYeNNX9iqW78hBCJZN+pW8gvVuK5KX5srInMREFJBbLkCt4lnxqELT+RCFKzinH84h1MDeqBXl3aiR0OEbWQhPRCAOD9wahBmIQRtTKNVoctUYlwbWuPOWF9xA6HiFrQjbRCuLSxQ1eZs9ihkAlgEkbUyg79lo4seRnmhPhyaCIiMyIIAhLSCxDYqyOvdKYGYRJG1Iru5ZfhYEwahvrJMKB3R7HDIaIWlF1QjiKFCv17S8UOhUwEkzCiVqITBGw9lAg7G2vMnthb7HCIqIXdSKvqDxbIHSxqICZhRK3k1JW7SL5TjL+O74V2zhyaiMjcJKQXws3Fnvf8owZjEkbUCgpLK/Hjr6nw6+6KUYGdxA6HiFqYTicgKaMQfTw7QML+YNRATMKIWsHOI8nQaHV4brIfG2giM5SRW4qyCg368NYU1AhMwogM7GKSHBeT5Xj8MS+4d3ASOxwiMoCEP/qD8Sat1BhMwogMqLxCg+1HktBN5ozQYd3FDoeIDORGeiE6d2wDV/b3pEZgEkZkQHtPpqKkTIV5HJqIyGypNTrczCziUTBqNP4qEBlIcmYRTlzKwqQh3dCjk4vY4RCRgdy6WwyVRoe+TMKokZiEERmAWqPD1qhEdGzngCdHe4sdDhEZ0I20QkgkgG93V7FDIRPDJIzIAH6OTcO9/HLMDfWFvZ212OEQkQElpBfCy8OFw5BRozEJI2phWXIFfo5Nxwh/d/TzdhM7HCIyIGWlBrfvlbA/GDVJqyVh//znP7Fy5crWKo5IFDpBwJaoRDja22DWBA5NRGTubt4pglYn8P5g1CStkoTFxsZi//79rVEUkah+/T0LqVklmDWhF1yc7MQOh+pw8OBBhIWFISQkBDt27Kh1uRMnTmD8+PGtGBmZkhtphbCxtkLvLu3EDoVMkMGTsKKiIqxduxaLFy82dFFEoiooqcDek6nw79EBI/09xA6H6pCTk4O1a9di586diIyMxO7du5GSkvLIcnl5efjnP/8pQoRkKhLSC9GriwvsbNn3kxrP4EnYu+++ixUrVsDFhZfok/kSBAHbDidBEATMDfXl0ERGLiYmBiNGjICrqyucnJwQGhqKqKioR5ZbtWoVli5dKkKEZApKylXIzFWgj1cHsUMhE2VjyBf/8ccf0alTJ4wcORL79u1r9Ppubs6NWl4qbdvoMkwR62l8Tl/OwpXUfMwP90ff3rJGrWtK9WwOY6pnbm4upFKpflomkyE+Pr7aMt9//z369u2L/v37N7mcxrRhxrR9DMmc6nnj9zsAgMcGdHmkXuZUz7qwns1j0CTsl19+gVwuxxNPPIHi4mKUl5fjo48+wttvv92g9fPzFdDphAYtK5W2hVxe2pxwTQLraXwUSjW+/s8VeHq0xcg+0kbFbUr1bI6G1NPKStLoHa+m0ul01Y5WCoJQbTo5ORnR0dHYsmULsrOzm1xOQ9swfg5MU+yVLLRxsIGrg021eplbPWvDev6pqe2XQZOw7777Tv//vn37cP78+QYnYESmYs+vKVAoNXjtr36wtuJdX0yBh4cH4uLi9NNyuRwy2Z9HMKOioiCXyzFz5kyo1Wrk5uZi9uzZ2LlzpxjhkhESBAHXbhfAv0cHWFmx+wE1DX8xiJohIb0QZ+LvIXR4N3R3t4zD8uYgKCgIsbGxKCgogFKpRHR0NMaMGaOfv2zZMhw+fBg//fQTNm/eDJlMxgSMqsnMVaC4TAX/HuwPRk3XaknYjBkz8PHHH7dWcUQGp1JrsTUqETJXRzzxWA+xw6FGcHd3x4oVKzB37lxMnz4d06ZNQ2BgIBYuXIirV6+KHR6ZgOu3CwAA/XrwhszUdAY9HUlkzg6cTUNuoRJvzBrAy9NNUHh4OMLDw6s998033zyyXNeuXXH8+PHWCotMxLXbBegqbYP2be3FDoVMGE9HEjVBRk4pos5lYFRAJ16eTmRhKlQa3LxTxKNg1GxMwogaSacTsOVQIpwdbfDU+F5ih0NErSwxowgarQB/b+6AUfMwCSNqpKNxmUjLLsXsST5wdrQVOxwiamXXbxXAzsYKPl05VBE1D5MwokbIK1Ji3+lbCOzphqF+jbspKxGZh2u38+Hn2R62NuwLSs3DJIyogQRBwPeHkyCRSDAnhEMTEVmi3CIlcgqVvDUFtQgmYUQN9NuNHFy7XYCZY7zh1s5B7HCISATXb+UDAPoxCaMWwCSMqAFKy1XYdfQmvDu7YPygrmKHQ0QiuXqrAG4uDvDo4CR2KGQGmIQRNcAPx1KgrNRg3hQ/DlFCZKFUai1upBWgfy83dkegFsEkjKge127nI/Z6NqaM8ERXaesMME1ExudGeiFUGh0G9O4odihkJpiEEdWhUqXF91FJ8OjghPAgT7HDISIRXUnJg72dNXy7tRc7FDITTMKI6hB55hbyiiswb4ofL0cnsmCCIOBKSh769egAWxv+dFLL4CeJqBa375Ug+kImxg7oDJ9urmKHQ0QiSs8pRZFChQG9eCqSWg6TMKIaaLQ6bD2UCJc2dogYy6GJiCzd5Zt5kAAI6MnxIqnlMAkjqsGRC5nIyFXg2Uk+cHKwETscIhLZ5ZQ89OzSDi5OdmKHQmaESRjRQ3IKyxF55jYG+Ugx2JdDExFZurxiJTJyFLwqklockzCiBwiCgO+jkmBjLcEzk3zEDoeIjMDFJDkAYLCvVORIyNwwCSN6wJmr95CQXoi/jO2F9m3txQ6HiIxAXFIuusuc4d6ed8mnlsUkjOgPxWUq7DmeAp+u7TBmQGexwyEiI1BQUoHUrBIM9mPXBGp5TMKI/rDraDIq1Vo8N8UPVhyShIgAXEyuOhU5hKciyQCYhBGh6k7Y5xNyMS3IC53c2ogdDhEZiYuJuegibcN2gQyCSRhZPGWlBtuik9ClYxuEjeDQRERUpVhRiZt3ijGEV0mTgTAJI4u379QtFJZU4rkpfrCx5leCiKqcT8yFAGAI+4ORgfAXhyxaalYxjl+8g/GDuqJXl3Zih0NERiT2Wja6uzujS0eeiiTDYBJGFkuj1WHLoUS4trXHjGBvscMhIiNyL78MadmlCPL3EDsUMmNMwshiHfotHVl5ZZgT6gtHew5NRER/irmWDYkEGN7XXexQyIwxCSOLdC+/DAdj0jDUT4YBvTgUCRH9SScI+O16Nvx7dEA7Z960mQyHSRhZHJ0gYOuhRNjbWmM2hyYioofczCxCfkklT0WSwRk8Cfvqq68wdepUTJ06FZ988omhiyOq16krd5F8pxhPjeuFdm3sxA6HRHLw4EGEhYUhJCQEO3bseGT+0aNH8cQTT+Dxxx/HkiVLUFxcLEKUJIazV7Nhb2uNgb15g1YyLIMmYTExMThz5gz279+PyMhIXL9+HUeOHDFkkUR1KiytxI+/pqCPZ3uMCuwkdjgkkpycHKxduxY7d+5EZGQkdu/ejZSUFP18hUKB9957D5s3b8aBAwfg6+uL9evXixgxtZbyCjXOJ+RgeF932NtZix0OmTmDJmFSqRQrV66EnZ0dbG1t0bNnT9y9e9eQRRLVaeeRZGi0AuZO9oWEQxNZrJiYGIwYMQKurq5wcnJCaGgooqKi9PPVajVWr14Nd/eqTtm+vr64d++eWOFSK4q5lg2VRoexAzl+LBmeQS8J6927t/7/tLQ0HDp0CLt27Wrw+m5uzo0qTypt26jlTRXr2TSxV+/iYrIcc8P6oJ+P8VzxxPez9eXm5kIq/fNUk0wmQ3x8vH66ffv2mDRpEgCgoqICmzdvxpw5cxpdTmPaMGPaPoZkzPUUBAGnr2ajdzdXDA3o0qzXMuZ6tiTWs3la5br8mzdvYtGiRXjzzTfh5eXV4PXy8xXQ6YQGLSuVtoVcXtrECE0H69k05RUabNh7Bd1kzhjl724025Dv55+srCSN3vFqKp1OV+1IqCAINR4ZLS0txcsvvww/Pz88+eSTjS6noW0YPwfGITmzCJk5pXh+il+z4jT2erYU1vNPTW2/DN4x/+LFi5g3bx7+9re/NakRI2oJe0+moqRMhXkcmogAeHh4QC6X66flcjlksupD0+Tm5mL27Nnw9fXFmjVrWjtEEsGJS1lwtLfBsD7Gc6SczJtBf43u3buHl19+GZ999hmmTp1qyKKIapWcWYQTl7IwaUg39OjkInY4ZASCgoIQGxuLgoICKJVKREdHY8yYMfr5Wq0WixcvxpQpU/DOO++w/6AFKCytxIXEXAT182CHfGo1Bj0d+e9//xuVlZX4+OOP9c/NmjULTz/9tCGLJdJTa3TYGpWIju0c8ORoDk1EVdzd3bFixQrMnTsXarUaERERCAwMxMKFC7Fs2TJkZ2fjxo0b0Gq1OHz4MACgX79+PCJmxo7EZUInCJg0tJvYoZAFMWgStmrVKqxatcqQRRDV6efYNNzLL8drT/Xn3i1VEx4ejvDw8GrPffPNNwCAgIAAJCYmihEWiaC8QoMTl7Iw1E8Gmauj2OGQBWHnGDJbWXIFfo5Nx0h/d/TzdhM7HCIyUicvZ6FCpcXk4d3FDoUsDJMwMks6nYAthxLhaG+Dv07oXf8KRGSR1BodouMy0cezPbw82GeUWheTMDJLv17KQurdEjw9oTdcnDg0ERHV7HT8XRQrVJgygkfBqPUxCSOzU1BSgb0nU9GvRweM8Oel5kRUs0qVFgfOpsGnazv4e3UQOxyyQEzCyKwIgoBth5MgCALmhHJoIiKq3ZG4TJSUqTBzbE+2FSQKJmFkVi4k5uJKaj6eHO0NKa9yIqJaKJRqHDqXgQG9OqJ3V1exwyELxSSMzIZCqcbOI8nw9GiLiUO6ih0OERmx/8akoaJSgxljeP9AEg+TMDIbe35NgUKpwfNT/GBtxY82EdUsM1eBo3F3MLp/J3SVtc54pUQ14S8VmYWEtAKcib+H0OHd0N3dMKPdE5Hp0/3Rb9TJwQYRY3uJHQ5ZOCZhZPJUai22RiVB5uqIJx7rIXY4RGTEzsTfQ0pWMf4yriecHW3FDocsHJMwMnkHzqYht0iJ5yb7ws6WQxMRUc0KSirw468p6N21HR4L6CR2OERMwsi0ZeSUIupcBkYFdEIf3ueHiGqh0wn45uANaLQC5k/tAyvekoKMAJMwMln3hyZydrTBU+PZt4OIavfLb+lIyizCsyE+cG/vJHY4RACYhJEJOxqXibTsUsye5MO+HURUq6SMQkSevo1hfWQI6uchdjhEekzCyCTJi5TYd/oW+vd0w1A/mdjhEJGRyikox1f7rsK9gyPmhvrxzvhkVJiEkcm5PzSRRCLh0EREVKuyCjXW7Y2HRCLB8ohAODnYiB0SUTVMwsjk/HYjB9duF2DmGG90cHEQOxwiMkLlFRqs3XMFeUVKLJ0RABn7gZERYhJGJqW0XIVdR2+iZ2cXjB/EoYmI6FHlFRr8vz2XkZ5diiXT+8GnG8eGJOPEY7NkUn44lgJlpQbPTfGDlRVPQxJRdUWKSnyxNx53chVYMr0fBvpIxQ6JqFZMwshkXLuVj9jr2QgP8kJXKcd7I6Lq0rNL8eV/4lFeocHLMwIwoFdHsUMiqhOTMDIJlSotvj+cBI8OTpgW5Cl2OERkRARBwMkrd/HDsZtwdrTF358dxDFkySQwCSOTEHnmFvKKK7DymUGwteHQRERUpVhRia1RSbickoe+Xu2xcFpftHO2FzssogZhEkZG7/a9EkRfyMTYAZ3ZwZaIAAAarQ5H4+7gwNnb0GgFPD2hNyYM6crhiMikMAkjo6bR6rD1UCJc2tghYiyHJiKydGqNDmev3cMvsenIK65A/55umDWhN9w78BYUZHqYhJFRi76QiYxcBV5+MoA3WiSyYAUlFTh15S5OXbmLIoUKPTq1xZxQXwR4u4kdGlGT8VeNjFZOYTl+OnMbg3ykGOzLy8yJLE1BSQV+T5bj92Q5kjKLAAHw79EB86d2g79XB46WQSaPSRgZJUEQ8H1UEmysJXhmko/Y4RBRKyguU+FmZhGS/3hk5CoAAJ07tsG0kV4YFdgJUldHkaMkajkGT8IOHjyIjRs3QqPR4LnnnsMzzzxj6CLJDBy7kIGE9ELMDfVF+7a80olaXn1tU0JCAt555x2UlZVhyJAheP/992Fjw/3W5tLqdCgsqYS8uAJ5xUrcyyvHHbkCd+QKFClUAAA7Gyv07NIOEWN7YpCPFB7s70VmyqAtSk5ODtauXYt9+/bBzs4Os2bNwvDhw9GrFztYU+2Ky1T494Hr8OnaDmMGdBY7HDJDDWmb3njjDXz44YcYMGAA3n77bezZswezZ88WMWrjoRMEVKq0qFT/8VBpUaHSQqWu+luh0kKhVKO0XIXS8qq/CqUapUo18ooqoBME/WvZWEvQ2a0N+np1QDeZM3p1bQdP97awseaoemT+DJqExcTEYMSIEXB1rbqtQGhoKKKiorB06dIWLedSshxXo5NRUalu0dc1Rg72tmZfz7t5ZahQaauGJmKfDzKA+tqmrKwsVFRUYMCAAQCAGTNm4MsvvzRIElZQUoFdx1NQoqiE8EdyIgiA8Mc/VX+rph+cjz+m76czVetULXj/+QeXq+l1/3xtATqdAK1WgFYnQKMToNXqoNVVTVf/X6iWRNXFxlqCtk52aOtoC2cnW3TzcIGzgzU6tnNEx3YO6NjOAW7tHGBtxYSLLJNBk7Dc3FxIpX92qJbJZIiPj2/w+m5uDRuaRnEtG0nphY2Oj4yUBFg8IwCBfh5iR9IqpFLLuLO3MdWzvrbp4flSqRQ5OTmNLqchbViZRkByRiFUGh0kAKr2OySQSB76H9B3RK+arnry/jxIJPr1Jfr/q5a3spI8su79/Zv701bWEthYWcHaWgIb6z/+1jJta20FB3ubqoedNRzsqv462tvA/o+/Lm3s4GhvY7Gd543p825IrGfzGDQJ0+l01b6AgiA06guZn6+ATlf/Htfofh6YMa435PLSJsVpSqTStqynGWE9/2RlJWnwjldz1dc2Nbftuq8hbVgbGwm+emO8eX0OdDqUlVag7KEq8fNuXljPPzW1/TLoMWAPDw/I5XL9tFwuh0wmM2SRRET1qq9tenh+Xl4e2y4ianEGTcKCgoIQGxuLgoICKJVKREdHY8yYMYYskoioXvW1TV26dIG9vT0uXrwIAPjpp5/YdhFRizPo6Uh3d3esWLECc+fOhVqtRkREBAIDAw1ZJBFRvWprmxYuXIhly5YhICAAn332GVatWgWFQgF/f3/MnTtX7LCJyMxIBKGBl7mIoKF9wgCemzY3rKd5MbY+Ya2loW0YPwfmhfU0LybbJ4yIiIiIasYkjIiIiEgERj0Gh5VV4y4Jb+zypor1NC+sZ8Pmm6LG1Mkc618T1tO8sJ4Nm18bo+4TRkRERGSueDqSiIiISARMwoiIiIhEwCSMiIiISARMwoiIiIhEwCSMiIiISARMwoiIiIhEwCSMiIiISARMwoiIiIhEwCSMiIiISARmkYStW7cO69ev10+XlJTgxRdfxJQpU/DMM89ALpeLGF3L2r9/P0aNGoUnnngCTzzxBNauXSt2SC3q4MGDCAsLQ0hICHbs2CF2OAYzZ84cTJ06Vf8+XrlyReyQWpRCocC0adNw584dAEBMTAzCw8MREhJidp/ZlsA2zHywDTN9rdp+CSaspKRE+Pvf/y4EBgYKX375pf75999/X9i0aZMgCIKwf/9+Yfny5WKF2OI++OAD4eDBg2KHYRDZ2dnCuHHjhMLCQqGsrEwIDw8Xbt68KXZYLU6n0wmjRo0S1Gq12KEYxOXLl4Vp06YJ/v7+QmZmpqBUKoXg4GAhIyNDUKvVwvz584UTJ06IHaZRYBtmXtiGmb7Wbr9M+kjYsWPH4OXlheeff77a8ydOnEB4eDgAYNq0aTh16hTUarUYIba4q1evYv/+/QgPD8frr7+O4uJisUNqMTExMRgxYgRcXV3h5OSE0NBQREVFiR1Wi7t16xYAYP78+Xj88cexfft2kSNqWXv27MHq1ashk8kAAPHx8fD09ES3bt1gY2OD8PBws3xfm4JtGNswU2TObVhrt18mnYRNnz4dL774Iqytras9n5ubC6lUCgCwsbGBs7MzCgoKxAixxUmlUixZsgQHDhxAp06d8MEHH4gdUot58H0DAJlMhpycHBEjMoySkhKMHDkSGzZswJYtW/DDDz/g7NmzYofVYtasWYMhQ4bopy3lfW0KtmFsw0yRObdhrd1+2bTYKxnQoUOH8I9//KPac97e3tiyZUuD1hcEAVZWppVvNqTOCxYswKRJk1o5MsPR6XSQSCT6aUEQqk2bi4EDB2LgwIH66YiICJw8eRKPPfaYiFEZjqW8r3VhG1aFbZh5sKQ2zNDvqUkkYVOmTMGUKVMavLxMJkNeXh48PDyg0WhQVlYGV1dXA0bY8mqqc2lpKbZs2YJ58+YBqPowPLwHbco8PDwQFxenn5bL5fpDwuYkLi4OarUaI0eOBFD1PtrYmMRXsUk8PDyqdSw31/e1LmzDqrANMw+W1IYZuv0yrV2rBgoODkZkZCQA4JdffsGQIUNga2srclTN5+TkhG+//VZ/Fcr27dvNai8yKCgIsbGxKCgogFKpRHR0NMaMGSN2WC2utLQUn3zyCSorK6FQKLB//36zeh8f1r9/f9y+fRvp6enQarX473//a5bva0tiG2aa2IaZH0O3X2aZui5fvhwrV67E1KlT0bZtW3z22Wdih9QirK2tsW7dOrz33nuoqKiAl5cXPvnkE7HDajHu7u5YsWIF5s6dC7VajYiICAQGBoodVosbN24crly5gunTp0On02H27NnVDu2bG3t7e3z88cd45ZVXUFlZieDgYEyePFnssIwa2zDTxDbM/Bi6/ZIIgiC02KsRERERUYOY5elIIiIiImPHJIyIiIhIBEzCiIiIiETAJIyIiIhIBEzCiIiIiETAJIyIiFpdQUEBnn/+eQwdOhRvv/12k14jODgYCQkJzYrj888/b9DIBREREbh582azyrpv/PjxiImJaZHXAhpeB0MqKSnBnDlzMGfOHAQHB2Pr1q0tus3MFZMwIxEcHIzr16/XOl+MhqIx5QKASqXCX/7yF1RUVODYsWN49913WyyOxqotloZuH0utN1Fr2bRpEzw9PXHhwgV89NFHGD16dKMSquLiYuTl5aFnz55NjqGgoACRkZGYNWtWvcvOnz8fX375ZZPLMpSH67B9+3bMmDED/fr1w8qVK1stDhcXF2zbtg2vvfYaxowZg2effdZot5kxYRLWDI1tNGpTXFyM3NxceHt71zhfrIaiMeUCgJ2dHZ566imsWbMG+/btEzUZqS2W2rZPTk6O/i7IllRvIrHExMTob3pZUFCAgoKCRiVUycnJ8PLygp2dXZNj2LdvH4KDg+Hg4FDvshMmTMC5c+eQm5vb5PIM4eE6yGQyLFmyBDNnzmzwa6xfvx7r169vdizx8fH48ccfsXr1alhbWxvtNjMmTMKaqCmNRm2Sk5PRtWtXODo61jhfrIaiMeXeN3DgQOzduxfvvvuuwccSk8vlePrppx953B/nq6ZYats+p06dwujRowEYtt4t0di1ZL2JmiszMxOLFi3C8OHDMXjwYDz//PMAqsYT3Lx5M8aNG4chQ4Zg+fLlKC0thUqlwuDBg5GcnIyXXnoJgYGBGDt2LHQ6HYYPH47hw4dDo9HgwIEDmDVrFl599VU89thjCA4OxsmTJ/XlJiUlwcfHBwCwdu1arFmzRj8vOzsbAzurFbQAACAASURBVAYMgE6nqzPGU6dOYejQodXqs3z5cv0A1QMHDoSvry+2b98Oe3t7+Pv74+zZsy2+DVNTUzFnzhwMGTIEU6dOxbFjx/Tzrl+/junTp2PgwIFYtmwZXn31Vaxdu1Y//+E6hISEYOLEiQYba3TPnj0ICwvD4MGDsWDBAuTn5wMArl27hl27duH999/XtzuG3GbmgklYE6Snpz/SaOTn52Px4sUICgrCoEGDsHjxYigUCv06u3btwosvvoj3338fw4cPx6hRo/QfzKSkJHTv3h0ffvghRowYUW0e8OiXrLZGAmjZD31NDRRQ+5ewsLAQH374IVasWIEDBw40u/z6ypNKpdi1a9cjD6lUWmsstW2fkydPIjg42OLqTdRcb775JsaMGYOYmBjExMRg6dKlAIB169bh9OnT2L17N86ePQuVSoUNGzbAzs4Ou3fvhpubGy5duoT4+Hi89dZbCA0NxaVLl3Du3DnY2NggOTkZN27cQEhICE6cOIG5c+fivffe05eblJQEX19fAEBCQgL8/Pz08xITE9GrVy9YWVnVGWNycjJ69OhRrT5ffPEFLl26hEuXLmHZsmXo06cPpk2bBgDo2bMnEhMTH9kGixYtwpAhQ2p8LFq0qM7tp1arsXjxYjz22GOIiYnBqlWr8Prrr+PWrVtQqVRYunQpnnzySZw/fx7Tpk3D0aNHq61fUx0M5euvv8YPP/yAjRs3IjY2Fu7u7li3bh0AYPHixbh9+zbmz5+PDz/8UL9ObduMqjAJawJPT89HGg2FQoE5c+bgxIkTOH78OAoLC/HDDz/o10lKSsLly5cxfvx4xMbGYtasWfjmm2/0865du4bg4GDExMRUmwc8+iWrq5EAWq6hqOnLXduXUKVS4a233sLf//53zJ8/H9HR0SgrK2v6Rq6nvLrUF8vD20etVuPChQsICgqyqHoTtYTMzExotVpotVrY29tj8ODByMvLw/bt2/HZZ59BJpPB3t4eoaGhuHbtGoCak6Y+ffpUe93k5GTMmzcPYWFhsLW1xfTp03H37l1UVlbq5z+YhN3///7rPThdU4xA1UDUbdq0qbFeW7duRWRkJL777jv9UaU2bdqgpKTkkWU3bdqEuLi4Gh+bNm2qc/tduXIF5eXlePHFF2FnZ4eRI0di3Lhx+Pnnn3HlyhVoNBrMnTsXtra2CAkJQUBAQLX166pDS8rPz8fGjRvx+eefw9PTE3Z2doiIiMDVq1cBAGfOnMEPP/yAbdu2YdWqVfr1attmVMUsB/BuDQ83Gp6envD09ARQ1S8nKCio2gcvKSkJCxcu1J/y6tmzJ+Li4gBUNSaLFy+ucR5Q+5fsfiOxZcuWaoee27RpU+Npp/oag4c9XO79L2FkZKS+rhEREXj//fdhZ2eHzZs365f98ccfG1VWTeoqry71xfLw9omLi4Ofnx+cnZ0BWE69iVrCp59+iq+//hobNmzAhAkT8OabbyIuLg4+Pj7/v707D2+qzvcH/k7SNt3pQrpBadnLViiLUmQRBUqBAlZUREXwgqPXYRiuo4+jXrzyXK/L4OAgo3dG/QmXTZCxLA5lUQTBMmzKKm3ZKXRJmq5Z2iY55/dHbWxLgbRNek6S9+t5eGiSk5z3N2m+/Zxzvud7EB0dbV+uoqICGo0GwK1F0/nz5zFhwoQmr5ufn4/Fixfbb+v1egQGBkKtVkMUReTn56NPnz4oKyuDXq9H79697cvm5ubaC63bZQwLC0NoaGiLG03r1q3Dli1bsGbNGoSHh9vvNxqNCA0Nbce7dSutVouYmBj7XjsAiIuLQ0lJCbRaLaKjo6FQKOyPxcbGNnn+7dpwN7/5zW9w4sQJALAXtmvWrAEADBs27Ja/F4cPH4bFYsEjjzxiv08URfTv3/+O63HFe+ZJWIS1UfNOIzs7G2vWrMG1a9dgsVhQU1ODZcuW2R/Pz89vsov2woUL6NWrl70zeffdd295rEFLX7LbdRKA837pm6+3rV/CBk899RSOHj3a4mNDhw7Fxo0bm9zX3vXdTvP3p/GhSMD57e6ozu5u2BmSK6SmpiI1NRV6vR4LFy5EVlYW1Go1QkJCmiz37bffIi0tDUD9Run06dMBAIIg4MKFC032jFVVVaGoqAgRERH2+3bv3m0/eebGjRtQKpXo0qULjhw5goSEBKjVagCA1WrFkSNHMGfOnDtmnD9/Pvr27YurV68iOTnZvuyGDRuwadMmrFmzpsn6gfqxWw25G1uwYIH9O97csGHD8Omnn972/YuKikJxcTEEQbAXYkVFRUhMTIRGo0FJSQlEUbQXYkVFRYiPj7c/v6U2OKJxv9MwTnXRokW3Xb6yshITJkxo9Qk+t3vPqB6LsDZo3mkcPnwYy5cvx4oVK+x/KB944AH7nrKGXeGND3H9/PPPmDBhAm7cuAEA9j0ejR9r0PxLdqdOAnBeR9F8vW39EjZYu3Ztq5Zv7/pup/n7c+DAAaxatcp+29nt7qjO7m7YGZKz7dmzB3369EFCQgKMRiOqqqrse5U/+OADXL9+HZGRkfj0009RWlpqP2MvNzcXL7/8MgCgpqYGNTU1EEXR/rr5+flQqVTYsWMHnnnmGRw6dAgbNmyw9yGNB+WLooiamhpYrVYolUr86U9/QllZmX1P2+0yAvVTAx07dsz+vdi0aRPWr1/fYt9aV1eHc+fO4Z133rnlfbhTkXU3ycnJCAgIwKeffor58+fjxx9/xL59+7BlyxbEx8dDpVJh3bp1ePzxx7F//36cOXMG99xzj/35zdtgtVphs9kgCAJsNhtqa2uhUqnafaJU//79sXLlSpw7dw4DBgyAwWDAv/71Lzz44INN9tQ1dqf3jOpxTFgbNO808vLyEBsbix49eqCqqgqvvvpqkzMnGzqMxrubG8ZENAwubfxL3Hy8RMOXDPi1k/j8889bLMAafukbxjc19umnn9rHkjX/11In0ni9QP2X8MiRI/b5zAwGA7755psmnaczuWJ9zd+fgoIC1NXVNTnL1RvaTeQMJ06cwJNPPomhQ4di4cKFePbZZ5GamopBgwbhueeew5w5czBu3DhcunQJa9asQUBAAHQ6HSorK+1T8gQGBmL27NmYMmWKfU9XXl4eMjIycPLkSYwYMQIrV67EX//6V/sRgsaD8ocPH46+ffsiPT0d8+fPR2xsLGJiYtCpU6c7ZgSAGTNm4MCBA6ipqQFQf9jy+vXrmDhxov3Ep61btwKo35N3zz33NDnE6gx+fn74+OOP8f3332PkyJF488038d5776Fnz57w8/PDhx9+iC1btmDEiBHYvn077r///ibTcjRvw8cff4zk5GT8/e9/x/bt25GcnIyPP/643TlTUlLwwgsvYNGiRUhJScGUKVNw8ODB2xZggOveM48iUpssXbpUTElJEceMGSOWlpaKjz32mDh48GBx1qxZ4qpVq8Tp06fbl121apX4n//5n/bbZWVlYv/+/cXa2lpx1apV4tKlS1t8rIFerxfHjBkjms1mcdiwYeLAgQPFIUOG2P9lZWXZl925c6f4wgsvOKWNjdfbYM2aNeL48ePFIUOGiGPGjGmS3RWcvb7m78/atWvFN998s8kyrmz3ypUrxZUrV951OVe3m0jOli5dKn7++ecdsq7333/foXXNmjVLzMvLc30gB3Js2bKlyX2OtqGjyeU9kzOFKLpoc56c6s9//jMiIiIwb968Oy73yCOP4K233rLvqu+o9bqL5u/PwoUL8eSTTzYZEwZ4fruJ5Ozxxx/H888/b98z5s2OHj2K7t27Izw8HDt27MAbb7yBb775BlFRUVJHIydgEUZe7ZNPPsFTTz3VqolZici1hg8fjq1bt6Jr165SR5Hcpk2b8Je//AUmkwnx8fF48cUXcf/990sdi5yERRgRERGRBDgwn4iIiEgCLMKIiIiIJMAijIiIiEgCsp6stbzcCEFwbMhaZGQw9HrD3Rd0c2ynZ2E7f6VUKhAe7vpr4HUkR/sw/h54FrbTs7iy/5J1ESYIosNFWMPy3oDt9Cxsp+dqTR/mLe8P2+lZ2M724eFIIiIiIgmwCCMiQv3loaZNm2a/nmtOTg4yMjIwadIkrFixQuJ0ROSJ2l2ENe+4Gjt//jwyMzORlpaG1157DVartb2rIyJyulOnTuHxxx/H1atXAdRfH/bVV1/FRx99hJ07d+Ls2bM4cOCAtCGJyOO0qwhr3nE199JLL2Hp0qXYvXs3RFHE5s2b27M6IiKX2Lx5M9544w37pWBOnz6NhIQExMfHw8fHBxkZGdi1a5fEKYnI07RrYH5Dx/Xyyy/f8tjNmzdRU1ODIUOGAAAyMzOxcuVKzJkzpz2rJJINURRhE0SIIiCI9QOwRVGE8MttUfjlZ0GEiJYHdYoqFfQV5juvp42P/RLybku4lNpXhU7BakkzOOKtt95qclur1UKj0dhvR0VFoaSkpNWvGxkZ7PCyGk1Iq1/fHbGdnsWT22mx2qBU1u+rclU721WENe+4GmveiWk0mjZ1YkQdxVxrRXGZCUV6I3QVNagy1aHKWIdqYx1qLDbUWgTUWWz1/6wCLFZB6siyp1AAbz5zj9t11IIgQKFQ2G+LotjktqP0eoNDZ1VpNCHQ6apb/fruhu30LJ7czlqLDctWH8PQPho8N2vIXdupVCpatdHVwGVTVDijE2ttg9yto28rttM5DGYLjpwtwumLpTh7qRTa8qZ7pEIC/RAW4ofQIDU6hfrD388Hal8V1H4qqH1V8PNVwUelgEKhgFKpgLLhfyV+/dn+/93S3HmBO3117v61an3x4CyB/j5ITooB4F6/tzExMdDpdPbbOp3OfqiSiDzftkNXUKQ3YUBihEvX47IirHknVlpa2upOzNGtSMCzK/LG2M72u3SzEnuPF+DH/FJYbQKCA3yR1C0MYwfHITYiEDGRgdCEBcBH5fqTh73h8yzTGxxqZ1u3JF1h8ODBuHLlCq5du4auXbvi66+/xsMPPyx1LCLqANeKq7H76HWMHRyLpIRwl67LZUVYly5doFarceLECQwbNgzbtm3D2LFjXbU6orvSlpuwZf8lHM/TIcjfB+MGx2HUoBgkxIRA2YZDTeS51Go13nnnHSxatAi1tbUYN24cJk+eLHUsInIxmyDg8+zzCAn0wyPje7l8fU4vwhYuXIjf/e53GDRoEJYvX47XX38dBoMBAwYMwNy5c529OiKHfH+qEBv25kOhUGDG6O5Iuyce/n6yvmAESWDfvn32n1NTU7F9+3YJ0xBRR9tzrADXSwz495kDEeTv6/L1OeWvUOOO65NPPrH/nJSUhC1btjhjFURtIogiNu+7iD3HCtAvIRwLpvVHeIj8z9YjIqKOpS03YdvBK0jp3RnD+mru/gQn4K4A8liiKOKLby7gmxM38ODQrnh8Qm8o7z5CnoiIvIwoilizKw9KpQJPTurbprOh24KXLSKPtftoAb45cQOTRsRjzkQWYERE1LKcs8U4f60cj9zfs0OPlrAII4+Ud70cW/ZfwrA+Gjz6QK8O26ohIiL3UmWswxffXkCvrp0wLqVLh66bRRh5nNo6Gz7753l0DvPHM1P78cxHIiK6rY3fXkCtxYanJyd1+N8LFmHkcbYeuozSyhrMT09CgJrDHomIqGWnL5XiyM8lmJqaiC6dgzp8/SzCyKNoy0345vgNjEmORd9urp1kj4iI3Je51or/252HuM5BmDIyQZIMLMLIo3z1/WWolArMHNND6ihERCRjWd9fRnlVLeZNToKvjzTlEIsw8hglZSYcO6/Fg8O7ci4wIiK6rUuFlfj2xA2MH9oFvbp2kiwHizDyGLuPFUClUmDS8HipoxARkUxZbQJWZ+ciLESNh8f1lDQLizDyCMYaC344U4RRA2PQKZh7wYiIqGXZR67jps6IJyf1kfzkLRZh5BH+da4EFquAB4Z2lToKERHJVJHeiB0/XMHwpCik9O6YSxPdCYswcnuiKOL7U4VIiA5Bt+gQqeMQEZEMCb9cmsjPR4UnJvSWOg4AFmHkAQq0BhRoDRidHCt1FCIikqnvTxUiv6ACjz7QSzbDVliEkds7lquFUqHAiH5RUkchIiIZKq+uxZffXUJStzCMkdEGO4swcmuiKOJ4rhZ9u4UhNNBP6jhERCRDG/bmw2IV8PTkJFldS5hFGLm1GzojSsrNGJHEvWBERHSrE3k6nMjXYcboRERHBEodpwkWYeTWTl4sBQCk9JH+LBciIpIXU40V6/bmIT4qGGn3dJM6zi1YhJFbO3NZj4SYEHQK4qFIIiJqasuBS6gy1mFeehJ8VPIreeSXiMhBxhoLLt2sxKAekVJHISIimckvqMD+n25i4vB4dI8NlTpOi1iEkds6d6UMoggkswgjIqJGLFYb1uzKRedO/nhoTA+p49wWizByW+evlSNArUL3OE7QSkREv/o65xqK9CbMTesLtZ9K6ji3xSKM3Fbe9Qr07hoGlZK/xkREVO+GzoCd/7qG1AHRGCjzIyX860VuqdJQi+IyE/p2C5M6ChERyYQgiFiTnYsAtQ8ee1Aelya6ExZh5JbyCioAAH3jwyVOQkREcvHdTzdxqbAKjz/Y2y0m8GYRRm4pr6ACaj8VEmKCpY5CREQyUFZVgy0HLmFg9wiMHBAtdRyHsAgjt3TpZiV6xoVyPBgREUEURazdnQdRFPFUWl9ZXZroTvgXjNxOrcWGG1ojesTJc94X8izbtm3D1KlTMXXqVLz77rtSxyGiFhzL1eLUJT0eGtMDmrAAqeM4jEUYuZ1rxdUQRBE94jpJHYU8nNlsxltvvYW1a9di27ZtOH78OHJycqSORUSNGMwWbNibj8SYEEwY3lXqOK3CIozczuXCKgDgnjByOZvNBkEQYDabYbVaYbVaoVarpY5FRI1s3ncRBrMV89KT3G6Iio/UAYha63JhJTp38neLM1/IvQUHB2Px4sVIT09HQEAARowYgaFDhzr8/MhIx08c0Wi8Y9JhttOzSN3OU/k6HDpThFkP9MawgXEuW4+r2skijNzOlaJq9OzCvWDkerm5ufjHP/6B7777DiEhIfjDH/6Azz77DAsWLHDo+Xq9AYIg3nU5jSYEOl11e+PKHtvpWaRuZ53FhpWbfkJUeAAmpMS5LIsj7VQqFa3a6LI/r62hiKRgMFugr6pBt2jv2MokaR06dAipqamIjIyEn58fMjMzcfToUaljERGAbT9cgbbCjKcnJ8HPV76XJroTFmHkVgpK6rdGukVzfjByvaSkJOTk5MBkMkEURezbtw+DBg2SOhaR17tWXI3dRwowJjkW/RLcd9JuHo4kt3KtxAAA3BNGHWL06NH4+eefkZmZCV9fXwwaNAjPPvus1LGIvJpNELB6Vy6CA33x6AO9pI7TLizCyK1c11YjPETNQfnUYZ599lkWXkQysvfYDVwrrsbzMwciyN9X6jjtwsOR5FaulxjQLYqHIomIvJG2woytBy9jSK/OGN5XI3WcdmtXEbZjxw5MmTIFkyZNwvr16295fNWqVRg/fjxmzJiBGTNmtLgMkaMsVgHFehPiOR6MiMjriKKItbtyoVQq8OSkPm5zaaI7afPhyJKSEqxYsQJfffUV/Pz8MHv2bNx7773o1evX47Nnz57Fn//8Z6SkpDglLHm3knITBFFEXOcgqaMQEVEHO3yuGOeuluOJiX0QEeovdRynaPOesJycHIwcORJhYWEIDAxEWloadu3a1WSZs2fP4m9/+xsyMjKwbNky1NbWtjswea/CUiMAIC6SRRgRkTepMtXhi28vomeXUIwf2kXqOE7T5iJMq9VCo/n1eGxUVBRKSkrst41GI/r164eXXnoJWVlZqKqqwkcffdS+tOTVCkuNUCiA2MhAqaMQEVEH+uLbCzDXWjEvvR+UHnAYskGbD0cKgtDkeKwoik1uBwUF4ZNPPrHffuaZZ/Dqq69iyZIlDq+jtbPPSn35hI7ire3UG+oQGxmEuNgwiRK5hrd+nkREjjh9SY9/nSvB9PsS0cXDhqO0uQiLiYnB8ePH7bd1Oh2ioqLstwsLC5GTk4NZs2YBqC/SfHxatzpHL/kBSH/5hI7ize28erMS0eEBHtV+b/48m2vrZT+IyHPV1FmxdnceYiMDMTU1Ueo4Ttfmw5GjRo3C4cOHUVZWBrPZjD179mDs2LH2x/39/fGnP/0JBQUFEEUR69evx8SJE50SmryP1SaguMzEQflERF4k6/sr0FfVYF56Enx9PG9WrTa3KDo6GkuWLMHcuXMxc+ZMTJs2DcnJyVi4cCHOnDmDiIgILFu2DM8//zwmT54MURQxf/58Z2YnL6KrMMMmiByUT0TkJS4XVuGbEwUYn9IFvbt61jCUBu2aMT8jIwMZGRlN7ms8DiwtLQ1paWntWQURgEZnRnJPGBGRx7PaBKzOPo+wYDUeHtdT6jgu43n79sgjFZYaoQAQwzMjiYg83u6j13FDZ8STE/sg0N9zr7DIIozcQqHehMhO/lD7qqSOQkRELlRcZsK2Q1cxvK8GKX3c/9JEd8IijNxCYamRhyKJiDycIIpYk50LXx8l5kzsI3Ucl2MRRrInCCKK9DwzkojI0x06XYS8ggo89kAvhAWrpY7jcizCSPZ0lWZYbQLPjCQi8mAVhlps3ncRfePDMCY5Vuo4HYJFGMlekd4EgJcrIiLyZBv25qPOKuDp9KQmV+DxZCzCSPZ05WYAQFR4gMRJiIjIFX7K1+F4ng7T70tETIT3bHCzCCPZ01WY4e+nQnCAr9RRiIjIycy1Vqzbm4+umiBMvreb1HE6FIswkj1dhRlRYQFes3uaiMibbDlwCRXVtZiX3g8+Ku8qS7yrteSWtBVmaMJ4KJKIyNNcuFGB7368iQnD49EjLlTqOB2ORRjJmiCKKK2sYRFGRORhLFYBq7NzERnqj4fGdpc6jiRYhJGsVRrqYLEK0IT5Sx2FiIic6J+Hr6JIb8JTaX3h7+e5lya6ExZhJGu6ivozIzU8M5KIyGPcLDXin4evYWT/aCT3jJQ6jmRYhJGs2YswHo4kIvIIDZcmClD7YPaE3lLHkRSLMJI1XYUZCgUQGcrDkUREnmD/Tzdx8WYlHnugF0ID/aSOIykWYSRr2gozIkP9ve60ZSIiT1RWVYMt+y9hQGI4Rg2MkTqO5PiXjWRNx+kpiIg8giiKWLcnH4IoYu5k77k00Z2wCCNZ01XU8MxIktS+ffuQmZmJ9PR0/Pd//7fUcYjc1rFcLU5eLMXM0T24cf0LFmEkW7V1NlQZ6/hlJckUFBTgjTfewEcffYTt27fj559/xoEDB6SOReR2DGYLNuzNR2JMCCaO6Cp1HNnwzok5yC3wzEiS2t69ezFlyhTExNSPXVmxYgXUarXEqYjcz+Z9F2EwW/EfjyVBpeT+nwYswki2WISR1K5duwZfX18899xzKCoqwv3334/f//73Dj8/MjLY4WU1mpC2RHQ7bKdncaSdJ/O1OHSmCI882BvDBsZ1QCrnc9XnySKMZItFGEnNZrPh+PHjWLt2LQIDA/H8888jKysLmZmZDj1frzdAEMS7LqfRhECnq25vXNljOz2LI+2stdjwly9+QnREICakxLnl++JIO5VKRas2uuzPa2soIlfTVpgRqPZBcICv1FHIS3Xu3BmpqamIiIiAv78/JkyYgNOnT0sdi8htbDt4BaWVNZg3uS98fVRSx5EdFmEkW/VnRnIvGEln/PjxOHToEKqqqmCz2XDw4EEMGDBA6lhEbuFKURV2H7uOcUPi0LdbuNRxZImHI0m2dBVmdNUESR2DvNjgwYOxYMECzJkzBxaLBffddx8efvhhqWMRyZ7VJmB1di5Cg/zwyP29pI4jWyzCSJZsgojSSjNS+nSWOgp5uVmzZmHWrFlSxyByK7uPXkeB1oDfZg5CoD9Ljdvh4UiSpbLKGlhtIg9HEhG5meIyE7YduophfTUY2kcjdRxZYxFGslRcZgTAMyOJiNyJIIpYk50LPx8lnpzYR+o4sscijGSpuLS+CItiEUZE5DYOnipEXkEFHn2gFzoFc2Lju2ERRrJUXGaCUqFARCi/xERE7qC8uhabv7uEpG5hGJMcK3Uct8AijGSpWG9EZCc1L29BROQm1u/Nh9Um4On0JCgUCqnjuAX+hSNZKtGbOB6MiMhNnMjT4sd8HWaO7o7o8ECp47gNFmEkS0V6I8eDERG5AWONBev25KNbdDAm3RMvdRy3wiKMZMdca0WVsY57woiI3MCX311EtcmC+en9OISklfhukezwwt1ERO7h/LVyfH+qCGn3xCMhJkTqOG6HRRjJDoswIiL5q7XYsGZXLqLCAjB9dHep47ildhVhO3bswJQpUzBp0iSsX7/+lsfPnz+PzMxMpKWl4bXXXoPVam3P6shL6CpqALAIIyKSs427c6EtN+PpyX2h9lVJHccttbkIKykpwYoVK7BhwwZs3boVmzZtwsWLF5ss89JLL2Hp0qXYvXs3RFHE5s2b2x2YPJ+uwoyQQF9eb4yISKauFVcj68AljEmORb/ECKnjuK02F2E5OTkYOXIkwsLCEBgYiLS0NOzatcv++M2bN1FTU4MhQ4YAADIzM5s8TnQ72gozoiODpI5BREQtsAkCVmfnIjTID48+0EvqOG6tzbsatFotNJpfL8wZFRWF06dP3/ZxjUaDkpKSVq0jMjK4VctrNN4xKNDT21lWXYteXcM8vp0N2E4icid7jhXgWkk1Xpk7AkH+vlLHcWttLsIEQWgyI64oik1u3+1xR+j1BgiC6NCyGk0IdLrqVr2+O/L0dgqCCG2ZCaMHx3l0Oxt4+ufZwJF2KpWKVm94EVHHKik3YevBK0jp3RmjkmNRWmqQOpJba/PhyJiYGOh0OvttnU6HqKio2z5eWlra5HGilpRV1cAmiIiO4OFIIiI5EUUR/7crDz4qBZ6c1JeXJnKCNhdho0aNwuHDh1FWVgaz2Yw9e/ZgYNedJAAAGY9JREFU7Nix9se7dOkCtVqNEydOAAC2bdvW5HGiljRMTxHbmZe9ICKSk0Oni3D+Wjkeub8XwkPUUsfxCG0uwqKjo7FkyRLMnTsXM2fOxLRp05CcnIyFCxfizJkzAIDly5fj7bffxuTJk2EymTB37lynBSfPpKusn54ihnvCiIhko9JQi037LqJPfBjGDomTOo7HaNccABkZGcjIyGhy3yeffGL/OSkpCVu2bGnPKsjL6CrMUCkViAwLQJmeYw2IiORg/d581FkFPD25L5Q8DOk0nDGfZEVbbkbnTv5QKfklJyKSgx/zdTiep8P0+xIRy+mDnIpFGMmKrsLMmfKJiGTCVGPFuj156KoJxuR7u0kdx+OwCCNZYRFGRCQfW/ZfRKWxDvOnJMFHxZLB2fiOkmyYaiww1lhZhBERyUDe9XLsP1mIicPj0T02VOo4HolFGMkGL9xNRCQPdRYbVmfnonMnfzw0pofUcTwWizCSjYY5wjRh/hInISLybtsOXUFJuRnz0pOg9lNJHcdjsQgj2dDaizDuCSMiksqVoirsOnodYwfHon9ihNRxPBqLMJINXYUZIYG+CFC3a/o6IiJqI6tNwOc7z6NTkB8eHd9L6jgej0UYyQbPjCS5evfdd/HKK69IHYPI5XYevoYbOiOeSuuLQH9fqeN4PBZhJBvachZhJD+HDx9GVlaW1DGIXO6GzoAdOVdxT78opPTWSB3HK7AII1mw2gSUVdWyCCNZqaiowIoVK/Dcc89JHYXIpQRBxOc7cxGg9sGciX2kjuM1WISRLJRV10IQRZ4ZSbKydOlSLFmyBKGhnCOJPNve4wW4UlSFORN7IzTQT+o4XoMjoEkWdOX1Z0ZGcU8YycSXX36J2NhYpKam4quvvmrTa0RGBju8rEYT0qZ1uBu2U34KSw3IOngF9/SPwbSxvaBoxQW63amd7eGqdrIII1nQlpsAAFHhgRInIaq3c+dO6HQ6zJgxA5WVlTCZTPif//kfvPrqqw6/hl5vgCCId11OowmBTlfdnrhuge2UH0EUsWLjT1ApgcfG90RpqcHh57pTO9vDkXYqlYpWbXQ1YBFGslBSboafjxJhwdwNTvLw+eef23/+6quvcPTo0VYVYETu4PuThci9XoF56UkID1FLHcfrcEwYyYK23Iyo8IBW7QYnIqK2K6uqwebvLqJfQjjGJMdKHccrcU8YyUJJuQmxkUFSxyBqUWZmJjIzM6WOQeQ0oiji/3bnQRBFPJ2exA1giXBPGElOEEToKsyIDuegfCKijvCvcyU4fUmPzLE9eUKUhFiEkeTKq2thtYmIYhFGRORyVcY6bPgmHz27hGLCsK5Sx/FqLMJIcjwzkoio46zfm49aiw3z0/tBqeRhSCmxCCPJlfwyRxgPRxIRudaP+Tocy9Ui477uiOvMcbhSYxFGktOWm+GjUiKMp0cTEbmMscaCtbvz0C0qGOn3dpM6DoFFGMlASbkJUeEBUPLsHCIil9mw9wKqTRbMn9IPPir++ZcDfgokOS3PjCQicqmTF0px+FwxpqYmICHGOy415A5YhJGkBFGE7peJWomIyPkMZgvW7MpFV00wMu5LlDoONcIijCRVaahDnVXgmZFERC6y4Zt8GMwWLJjGw5Byw0+DJFVS1jA9BfeEERE520/5OvzrXAmmpiagWzQPQ8oNizCSlLbil+kpOGMzEZFTGcwWrNmdh/ioYEwblSh1HGoBizCSVEmZCT4qBSJC/aWOQkTkUdbvzYfRbMG/TeVhSLnip0KSKtKbEB0RyFmbiYic6ESeDkd+LkHGqEQehpQxFmEkqcJSI7pw1mYiIqepNtVh7e5cdIsOxpTUBKnj0B2wCCPJ1Fls0FWYERfJIoyIyFnW782HscaKf5van4chZY6fDkmmuMwEEeD1y4iInOR4rhZHz2sx/b5ExEcFSx2H7oJFGEmmsNQIAIhlEUZE1G5Vpjqs3ZOHhOgQpI/kYUh3wCKMJFOoN0KlVPCSRURE7SSKItZk58Jca+XZkG6EnxJJprC0/sLd7CyIiNrnhzPF+OlCKTLH9kRXHoZ0Gz5tfWJhYSFeeukl6PV6dO/eHcuXL0dQUNPDSjdv3sS0adPQrVs3AEDnzp3x2WeftS8xeYybpUZ01fBQJBFRe5RWmLHhm3z0iQ/DpBHxUsehVmjzLog333wTc+bMwa5duzBw4EB89NFHtyxz9uxZZGRkYNu2bdi2bRsLMLKzWAVoy008M5KIqB0EQcSnX/8MAFgwtR/nXHQzbSrCLBYLjh07hrS0NABAZmYmdu3adctyZ86cQX5+PmbMmIG5c+ciLy+vfWnJY5SUmSCKPDOSiKg9dh+7jvwblXhiYh905uXf3E6bDkeWl5cjODgYPj71T9doNCgpKbllObVajenTp2P27Nk4ePAgXnjhBezcuRN+fn4OrScysnXHtTUa75gV2BPamXujCgAwoLfmtu3xhHY6gu0korYo0BqQ9f1lDO2jwaiBMVLHoTa4axGWnZ2Nt99+u8l9CQkJUCia7vJsfhsAFi1aZP953LhxeP/993H58mUkJSU5FE6vN0AQRIeW1WhCoNNVO7SsO/OUduZeKYVCAagVYovt8ZR23g3b+SulUtHqDS8ib2WxCvhkxzkE+vti7uS+Lf4NJvm7axGWnp6O9PT0JvdZLBbce++9sNlsUKlU0Ol0iIqKuuW5a9euxbRp0xAeHg6g/hTahr1n5N0KS42ICguAr49K6ihERG4n6+Bl3NAZsXhWMkIDHTu6RPLTpjFhvr6+GD58OHbu3AkA2Lp1K8aOHXvLcseOHcOWLVsAAEePHoUgCOjRo0c74pKnuFlqRCwH5RMRtdr5q2XYfeQ6xg2Jw+BenaWOQ+3Q5rMj33jjDWzevBlTpkzB8ePH8fvf/x4AsHHjRvzlL38BALz22mvIycnBtGnT8O677+L999+HUsk5obxdrcWG4jITL6lBRNRK1aY6/P3rnxEdEYjZD/SWOg61U5uPDXbp0gVr16695f7HH3/c/nN0dDQ+//zztq6CPNQNnQGiCHSL5kBtIiJHiaKIz3fmwmi2YMkjg6H243AOd8cBWtThrpcYAAAJ0dwTRvK3atUqZGdnA6g/wejll1+WOBF5q30/3sTJi6V4/MHe3Ij1EDw2SB3uekk1gvx9ENnJX+ooRHeUk5ODQ4cOISsrC1u3bsW5c+ewd+9eqWORFyrQGrBp30Uk94zEhOFdpY5DTsI9YdThrpdUIz4qmKdUk+xpNBq88sor9rkNe/bsicLCQolTkbeptdjwv9vOIsjfB89M7ce+04OwCKMOZbUJuKEzYnxKF6mjEN1V796/Dny+evUqsrOzsXHjRoef35p5z7xlMlu2s/U+3HwSxWUmLHs2FT0TIp32us7Az7N9WIRRh7qpM8JiFZAY6x1fXPIMFy5cwG9+8xu8/PLLSExMdPh5jk44zUl7PYsz2/nDmSLsOXINU1MT0CU8QFbvHz/PX7V1smmOCaMOdbmwEgDQM66TxEmIHHPixAnMmzcPL774Ih566CGp45AXuaE1YO3uPCR1C8PMMd2ljkMuwD1h1KEuF1YhJNAXnTkon9xAUVERXnjhBaxYsQKpqalSxyEvYq614q9ZZxDg74PfzBgIFefY9EgswqhDXS6qQs+4ThxYSm7hs88+Q21tLd555x37fbNnz24yHyKRs4miiP+38zx0FTV4eU4KOgXxskSeikUYdRhTjQVFehNGDoiROgqRQ15//XW8/vrrUscgL7P3WAFO5Onw6Phe6BMfJnUcciHu36QOc/Fm/XiwXnGhEichIpKn/IIKfLn/ElJ6d0baPfFSxyEXYxFGHSbvegVUSgV6dOGgfCKi5korzfhr1hl0DgvAv3E+MK/AIow6TF5BBbrHhULty+udERE1VlNnxYf/OAOrTcTvHh6EQH9fqSNRB2ARRh2ips6Kq0XV6MvxDURETQiiiM/+eR43dAY8P2MAYiODpI5EHYRFGHWIizcqIYgikrqFSx2FiEhWth+6Yh+IP7CHvGbEJ9diEUYd4uyVMviolOjVlePBiIgaHDxdiO0/XMV9g2IwaQQH4nsbFmHUIc5c1qNvtzCOByMi+sWZy3qsyc5D/8RwPD05iQPxvRCLMHK50gozivQmDOJudiIiAMC14mp8lHUWXTVBeOGhQfBR8c+xN+KnTi53+rIeADCoR4TESYiIpKctN2HFl6cQHOCDxY8MRoCa86Z7KxZh5HIn8nSIjghETESg1FGIiCRVWmnGnzb+BJtNwO8fHYLwELXUkUhCLMLIpapMdci9Xo4RSRqOdyAir1ZWVYP3NvwEc60Nf5idgi6dORWFt2MRRi71Y74OoggM7xsldRQiIslUGGrxp40/wWC24D8eG4KEmBCpI5EM8EA0udSRcyWIDg9AfFSw1FGIiCShr6zB+5tOosJQhxcfG4IevH4u/YJ7wshlSspMyCuowOjkWB6KJCKvdLPUiP9ZdwKVxjoseXQw50qkJrgnjFzm4OkiKBUKjBoYK3UUIqIOd+lmJT748hR8VEq88sRQHhGgW7AII5eos9hw8HQhkntG8uwfIvI6J/J0+OTrc+gU5IcXZ6cgKixA6kgkQyzCyCVyzhaj2mRB2j28DAcReQ9BFLEu+zw2fZOP7rGh+N3Dg9ApmBui1DIWYeR0VpuAXUevo3tsCPrEh0kdh4ioQ5hqrPhkxzmcuqTH6ORYPDWpD3x9eKk2uj0WYeR0B08XQVtuxqKHB3FAPhF5hYs3K/HJjnMoq6rFcw8Nwog+ndn/0V2xCCOnMtdase3QFfTp2glDenWWOg4RkUtZrAL+efgqvs65hohQNV6ek4JRKfHQ6aqljkZugEUYOdWX+y+h2lSHxbOSuRVIRB4tv6ACa3blokhvQuqAGDwxsQ8C/flnlRzH3xZymrNX9Nj/001MGhGP7rGcjJCIPJO23ISsg1dw5OcSRIb64/ePJCO5J/f8U+uxCCOnKK004+/bf0YXTRAeGttD6jhERE5XaazD1z9cxf6TN6FSKjA1NQHTUhOh9uPge2obFmHUbpXGOry/6RRsgojfPjQIal92SETkOW5oDdh7vACHz5VAEESMHRKH6fclIoxTT1A7sQijdtFVmPHnzadQXl2DFx8bguiIQKkjERG1m7nWipMXSnHoTBHOXyuHn68So5NjkTYinv0cOQ2LMGoTURTxY74Oq7NzAQD/8egQ9O7KOcGIyH0ZzBb8fLUMJ/J0OHWxFHVWAZGh/njk/p4YMzgOwQG+UkckD8MijFrtanEVNu+7iNzrFUiIDsFzMwZwy5CI3I7BbMGVoipcvFGJc1fLcKWoCqIIhAT6YnRyLO7tH42eXTpByTO9yUXaXYR98MEHUKlUWLRo0S2P1dXV4bXXXsPZs2fh7++P5cuXo2fPnu1dJUmg2lSHn37ZNX/xRiWCA3zxxMQ+GDckDj4qpdTxiFxmx44d+Pjjj2G1WvH000/jiSeekDoStVJtnQ3FZSYU6Y0o0tf/f11rgLbcDABQKIAesaHIGJWIgd0j0T0uBCol+zVyvTYXYdXV1Xj77bfxz3/+EwsWLGhxmbVr1yIgIADZ2dk4duwY/vjHP2Lz5s1tDkuuZ7EKqDDU/tJhmVCsN+LCzUrc1BkBALGRgZh1f0/cP6QL58Mhj1dSUoIVK1bgq6++gp+fH2bPno17770XvXr1kjqa1xJFERargDqrAFOtFUazBUazBYYaC4xmKwxmCyoNtSirrkVFdf3/BrPF/nyFAtCEBaCrJhhjB8ehe2woEmNCEKBmf0Ydr82/dd9++y0SExMxf/782y6zf/9+LF68GAAwYsQIlJWVobCwEHFxcW1dbYtu6AzIOa+FwVALiKL9/oafGt3VhNiwhNj4vobntPwk8dan2O9sep9jrym2sFzjW82fEhjoB6OxrtFSt75ASzlEiLDZRNRZBdRZbbBY6juxOoutvjOrsaDKZIG51tpkfUH+PkiICcG9/aIxoHsEEmNCOAkreY2cnByMHDkSYWH14x3T0tKwa9cu/Pa3v3XaOmrqrMg+fBVl5aZb+pLm3//mfdbt+pZb+qnmfVRrn3+b/khs1L80W/SWdQmiCD+1D4zGOtgEATZBhCCIsDX8s4kQxIafBQhCQ39V30/VWmyos9T/fJsu3S44wBcRIWqEh6jRo0snRISoERMRiNjIQESFB8LXh3u5SB7aXITNnDkTAPDhhx/edhmtVguNRmO/rdFoUFxc7HARFhkZ7NByXx64jOzDVx1aVo4a1zSKFh5QtLisooX7Gt2ruPVxH6UCfr4qqP1U9f/71v8fFOiH+OgQdApRo1OwH8KC/dE1Khhdo4IRGuQnWdGl0YRIst6OxnbKV/M+LCoqCqdPn3b4+Y70YWcvleJ//3EKwt0qiw7W8LVv3qcomj3eUl90y3MU9fepVEr4qBRQKRVQqZT1/yuVUKkU8FEqoVQp4KNUQOWjgp9SgdBf+im13y//fvnZ388Hal8VAtQ+CA3yQ0igH4IDfe3/y2GIhDv+vrcF29k+dy3CsrOz8fbbbze5r0ePHli9evVdX1wUxSZ/wEVRhLIVx9n1egMEB3qmh8d2x9yp/aEvbbhWV8sFSkv3KdC812ipk3H8NRUtvVCT12xfQaPRhHTYNcnqzHUoNdfdfUEX6Mh2Sont/JVSqXB4w6ujCIJwSx/Wmu+wI31YdKgaX7w1FVpt1S/3/Fq4NHZLH9Os62peFLX++a7f2HL177ulpg7lNdL0WY3xe+1ZXNl/3bUIS09PR3p6eqtfGACio6Oh1WrRrVs3AEBpaSmioqLa9Fp3olQoEBzgC7M/Tx8mIueJiYnB8ePH7bd1Op1L+rAAtQ8C2X8ReR2X7rMdN24ctm3bBgA4fvw41Gq108eDERG5yqhRo3D48GGUlZXBbDZjz549GDt2rNSxiMhDOP10kI0bN0Kr1WLx4sV46qmnsHTpUkydOhV+fn547733nL06IiKXiY6OxpIlSzB37lxYLBbMmjULycnJUsciIg+hEG93GqAMODomDOCxaU/DdnoWdx0T1l6O9mH8PfAsbKdncWX/Jf0pJEREREReiEUYERERkQRkPUWwUtm6U6Zbu7y7Yjs9C9vp2OPuqDVt8sT2t4Tt9Cxsp2OP346sx4QREREReSoejiQiIiKSAIswIiIiIgmwCCMiIiKSAIswIiIiIgmwCCMiIiKSAIswIiIiIgmwCCMiIiKSAIswIiIiIgmwCCMiIiKSAIswIiIiIgl4RBH2wQcf4MMPP7TfrqqqwrPPPov09HQ88cQT0Ol0EqZzrqysLIwePRozZszAjBkzsGLFCqkjOdWOHTswZcoUTJo0CevXr5c6jss89dRTmDp1qv1zPHXqlNSRnMpgMGDatGm4ceMGACAnJwcZGRmYNGmSx/3OOgP7MM/BPsz9dWj/Jbqxqqoq8Y9//KOYnJwsrly50n7/m2++Kf7tb38TRVEUs7KyxMWLF0sV0emWLVsm7tixQ+oYLlFcXCyOHz9eLC8vF41Go5iRkSFeuHBB6lhOJwiCOHr0aNFisUgdxSVOnjwpTps2TRwwYIBYUFAgms1mcdy4ceL169dFi8UiPvPMM+L+/fuljikL7MM8C/sw99fR/Zdb7wn79ttvkZiYiPnz5ze5f//+/cjIyAAATJs2Dd9//z0sFosUEZ3uzJkzyMrKQkZGBv7whz+gsrJS6khOk5OTg5EjRyIsLAyBgYFIS0vDrl27pI7ldJcvXwYAPPPMM5g+fTrWrVsncSLn2rx5M9544w1ERUUBAE6fPo2EhATEx8fDx8cHGRkZHvm5tgX7MPZh7siT+7CO7r/cugibOXMmnn32WahUqib3a7VaaDQaAICPjw+Cg4NRVlYmRUSn02g0+Pd//3ds374dsbGxWLZsmdSRnKbx5wYAUVFRKCkpkTCRa1RVVSE1NRV//etfsXr1anzxxRf44YcfpI7lNG+99RaGDx9uv+0tn2tbsA9jH+aOPLkP6+j+y8dpr+RC2dnZePvtt5vc16NHD6xevdqh54uiCKXSvepNR9q8YMECTJw4sYOTuY4gCFAoFPbboig2ue0pUlJSkJKSYr89a9YsHDhwAPfdd5+EqVzHWz7XO2EfVo99mGfwpj7M1Z+pWxRh6enpSE9Pd3j5qKgolJaWIiYmBlarFUajEWFhYS5M6Hwttbm6uhqrV6/GvHnzANT/MjTfgnZnMTExOH78uP22Tqez7xL2JMePH4fFYkFqaiqA+s/Rx8ctvoptEhMT02Rguad+rnfCPqwe+zDP4E19mKv7L/fatHLQuHHjsHXrVgDAzp07MXz4cPj6+kqcqv0CAwPx6aef2s9CWbdunUdtRY4aNQqHDx9GWVkZzGYz9uzZg7Fjx0ody+mqq6vx3nvvoba2FgaDAVlZWR71OTY3ePBgXLlyBdeuXYPNZsPXX3/tkZ+rM7EPc0/swzyPq/svjyxdFy9ejFdeeQVTp05FSEgIli9fLnUkp1CpVPjggw/wX//1X6ipqUFiYiLee+89qWM5TXR0NJYsWYK5c+fCYrFg1qxZSE5OljqW040fPx6nTp3CzJkzIQgC5syZ02TXvqdRq9V45513sGjRItTW1mLcuHGYPHmy1LFkjX2Ye2If5nlc3X8pRFEUnfZqREREROQQjzwcSURERCR3LMKIiIiIJMAijIiIiEgCLMKIiIiIJMAijIiIiEgCLMKIiIiIJMAijIiIiEgC/x8qwarFw3kU/wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x576 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "\n",
    "sns.set() \n",
    "\n",
    "x = np.arange(-10, 10, 0.1)\n",
    "y_relu = [max(0, i) for i in x]\n",
    "y_sigmoid = [1.0/(1+np.exp(-i)) for i in x]\n",
    "y_tanh = [(np.exp(i)-np.exp(-i))/(np.exp(i)+np.exp(-i)) for i in x]\n",
    "y_softplus = [np.log(1+np.exp(i)) for i in x]\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "axs[0][0].plot(x, y_relu)\n",
    "axs[0][0].set_title(\"$ReLU(z) = \\max(0, z)$\")\n",
    "\n",
    "axs[0][1].plot(x, y_sigmoid)\n",
    "axs[0][1].set_title(\"$sigmoid(z) = {1}/(1+e^{-z})$\")\n",
    "\n",
    "axs[1][0].plot(x, y_tanh)\n",
    "axs[1][0].set_title(\"$tanh(z) = (e^x-e^{-x})/(e^x+e^{-x})$\")\n",
    "\n",
    "axs[1][1].plot(x, y_softplus)\n",
    "axs[1][1].set_title(\"$softplus(z) = \\log(1+e^z)$\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 正则化\n",
    "\n",
    "### 5.1 批标准化(Batch Normalization)  \n",
    "\n",
    "BN 方法会针对每一批数据，在网络的每一层输入之前增加归一化处理，使输入的均值为 0，标准差为 1。目的是将数据限制在统一的分布下。\n",
    "\n",
    "#### 5.1.1 算法原理   \n",
    "具体来说，针对某层的第 k 个神经元，计算这一批数据在第 k 个神经元的均值与标准差(每个数据在该神经元产生一个值，如果这批数据大小是m，那么就产生m个值，然后计算这些值的均值和标准差)，然后将归一化后的值作为该神经元的激活值。\n",
    "$$\\hat{x_k} \\leftarrow \\frac{x_k-\\rm E(x_k)}{\\sqrt{(\\rm Var(x_k))}}$$\n",
    "BN 可以看作在各层之间加入了一个新的计算层，对数据分布进行额外的约束，从而增强模型的泛化能力；\n",
    "但同时 BN 也降低了模型的拟合能力，破坏了之前学到的特征分布；\n",
    "为了恢复数据的原始分布，BN 引入了一个重构变换来还原最优的输入数据分布,\n",
    "$$y_k \\leftarrow \\gamma \\cdot \\hat{x_k} + \\beta$$\n",
    "其中$\\gamma$和$\\beta$是可训练参数  \n",
    "\n",
    "上面的算法框架如下， \n",
    "![](../../../pics/batch_norm.png)\n",
    "\n",
    "#### 5.1.2 单个样本计算(移动平均)\n",
    "\n",
    "训练时，按照mini-batch方式训练，可以使用上述的方式进行运算，但是当网络仅仅输入一个样本时，此时显然使用上述方法欠妥，此时模型使用**全局统计量**代替上述的批统计量。    \n",
    "1）在训练每个batch时，可以预先存储每个batch的均值和方差   \n",
    "2）最后求所有的batch的均值和方差的期望，  \n",
    "$$\\rm E[x] \\leftarrow \\rm E[\\mu_i]$$\n",
    "$$\\rm Var[x] \\leftarrow \\frac{m}{m-1} \\rm E[\\sigma_i^2]$$\n",
    "其中$\\mu_i$和$\\sigma_i$表示第i轮的均值和标准差,m为batch_size，系数$\\frac{m}{m-1}$用于计算**无偏方差估计**\n",
    "> Note: 上述方式在原论文中称为**移动平均(moving average)**\n",
    "\n",
    "目前的$\\rm{BN}(x_i)$可以表示为\n",
    "$$\n",
    "\\begin{equation}\\begin{split} \n",
    "\\rm{BN}(x_i) &= \\gamma \\frac{x_i-\\rm E[x]}{\\sqrt{\\rm Var[x] + \\epsilon}} + \\beta \\\\\n",
    "&= \\frac{\\gamma}{\\sqrt{\\rm Var[x] + \\epsilon}}x_i + \\left(\\beta - \\frac{\\gamma \\rm E[x]}{\\sqrt{\\rm Var[x] + \\epsilon}}\\right)\n",
    "\\end{split}\\end{equation}\n",
    "$$\n",
    "以上整体算法如下，\n",
    "![BN_train_predict](../../../pics/BN_train_predict.png)\n",
    "\n",
    "#### 5.1.3 为什么训练时不采用移动平均\n",
    "BN author:  \n",
    "> \"It is natural to ask whether we could simply use the moving averages µ, σ to perform the normalization during training, since this would remove the dependence of the normalized activations on the other example in the minibatch. This, however, has been observed to lead to the model blowing up. As argued in [6], such use of moving averages would cause the gradient optimization and the normalization to counteract each other. For example, the gradient step may increase a bias or scale the convolutional weights, in spite of the fact that the normalization would cancel the effect of these changes on the loss. This would result in unbounded growth of model parameters without actually improving the loss. It is thus crucial to use the minibatch moments, and to backpropagate through them.\"\n",
    "\n",
    "\n",
    "简言之，作者认为训练时使用移动平均可能会和梯度优化存在冲突，在网络在使用梯度优化时，会对权重增加一些偏移，但是在使用BN后，可能会将这些偏移抵消掉。\n",
    "\n",
    "#### 5.1.4 BN的作用\n",
    "\n",
    "- 允许较大的学习率，加快模型收敛速度   \n",
    "BN通过固定网络层输入（也即前一层的响应）的分布（标准正态）使优化过程中的解空间更平滑，从而确保了梯度更具预测性和稳定性，因此可以使用更大范围的学习率并获得更快的收敛速度。\n",
    "\n",
    "- 避免深层网络的梯度消失或爆炸问题   \n",
    "BN通过固定网络层输入的均值和方差，即使网络较深层的响应或梯度过小或过大时，也可通过BN的规范化作用将其缩放到一个比较合理的取值范围，从而避免梯度消失或爆炸问题。\n",
    "\n",
    "- 减少对参数初始化方法的依赖    \n",
    "Xavier等参数初始化的目的是为了使网络各层的输入输出具有相同的统计分布，而BN直接对网络层构造标准正态分布的响应，能够达到同样的目的。 \n",
    "\n",
    "#### 5.1.5 BN相关阅读  \n",
    "- [深入理解Batch Normalization批标准化](https://www.cnblogs.com/guoyaohua/p/8724433.html)\n",
    "- [BN具体做法](https://blog.csdn.net/u010899985/article/details/82251932)\n",
    "\n",
    "\n",
    "### 5.2 L1/L2正则\n",
    "\n",
    "参考本项目 **算法篇/basic_concepts/Regularization.ipynb**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Dropout\n",
    "\n",
    "在每个训练批次中，令部分隐藏层节点取值为0，可以减少隐含层节点间的相互作用，可以明显减少过拟合现象。\n",
    "\n",
    "或者说网络在向前传播时，令神经元的激活值以概率$p$删除(每个神经元以概率$1-p$保留，$p$丢弃)，这样可以增加模型的泛化能力。\n",
    "\n",
    "#### 5.3.1 训练时流程 \n",
    "1）随机地按照按照dropout rate删掉部分神经元，输入输出神经元保持不变   \n",
    "2）输入的批量样本前向传播，然后反向更新网络权重（没有删除的），按照比例$\\frac{1}{1-p}$放缩网络权重，完成一次训练    \n",
    "3）恢复删除的神经元，然后重复步骤1）和步骤2）    \n",
    "> Note: 上面提到的删掉部分神经元是指以概率$p$产生0或者1(伯努力分布)，然后将0或者1乘对应的权重，0值对应的权重相当于删除神经元  \n",
    "\n",
    "- 放缩比例$\\frac{1}{1-p}$的确定   \n",
    "不妨假设某个神经元的dropout前的取值为$x$，个数为$n$，dropout后的期望为$E = p\\cdot 0 + (1-p)x$，要想整体期望在删除神经元前后保持一致，\n",
    "$$E \\cdot \\rm{scale} = x$$\n",
    "则有放缩比例$\\rm{scale}=\\frac{1}{1-p}$   \n",
    "\n",
    "#### 5.3.2 预测时流程  \n",
    "预测阶段不同于训练阶段，此时不可以随机删除神经元，否则同一个输入可能存在多个不同的预测结果，为了和训练dropout保持一致，采取的策略是将取值调整为$x\\rightarrow (1-p)x$\n",
    "- 放缩$x \\rightarrow (1-p)x$的确定    \n",
    "考虑某一个隐含层的神经元在dropout之前的输出是$x$，在dropout之后的期望值为$E = (1-p)x+p0$，所以为了保持前后期望的一致，即\n",
    "$$x \\cdot \\rm{scale} = E$$\n",
    "于是有将神经元的值调整为$x \\rightarrow (1-p)x$   \n",
    "\n",
    "\n",
    "#### 5.3.3 dropout的作用\n",
    "\n",
    "1）加快训练速度   \n",
    "通过随机将删除神经元，相当于减少了需要学习的参数，可以加快训练\n",
    "\n",
    "2）降低过拟合  \n",
    "- 类似baggin策略    \n",
    "可以把dropout类比为将许多神经网络进行集成的bagging方法（bagging参数独立，dropout参数共享）。dropout每次训练次均随机删除掉神经元，相当于每次训练得到一个模型，最后综合这些模型结果得到最终的结果.\n",
    "\n",
    "- 减少神经元之间的依赖   \n",
    "这样权值的更新不再依赖于有固定关系的隐含节点的共同作用，阻止了某些特征仅仅在其它特定特征下才有效果的情况 。迫使网络去学习更加鲁棒的特征 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. References\n",
    "\n",
    "1. 弗朗索瓦$\\cdot$肖莱. Python 深度学习[M]. 人民邮电出版社 \n",
    "2. 周志华. 机器学习[M]. 清华大学出版社\n",
    "3. https://github.com/imhuay/Algorithm_Interview_Notes-Chinese/\n",
    "4. [深度学习中Dropout原理解析](https://blog.csdn.net/program_developer/article/details/80737724)\n",
    "5. [梯度下降优化算法综述\n",
    "](https://blog.csdn.net/google19890102/article/details/69942970)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "783px",
    "left": "222px",
    "top": "206px",
    "width": "317px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
